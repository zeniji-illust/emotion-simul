"""
Zeniji Emotion Simul - Brain (The Director)
ìµœìƒìœ„ í†µì œ ëª¨ë“ˆ: í”„ë¡¬í”„íŠ¸ ì¡°ë¦½, LLM í˜¸ì¶œ, JSON íŒŒì‹±, VRAM êµëŒ€ ê²°ì •
"""

import json
import re
import logging
from typing import Dict, Optional, Any
from state_manager import CharacterState, DialogueHistory, DialogueTurn
import config
from logic_engine import (
    interpret_mood, check_badge_conditions, check_status_transition,
    apply_gacha_to_delta, get_trauma_instruction,
    get_intimacy_level, get_trust_level, get_dependency_level,
    apply_trauma_on_breakup, validate_status_transition_condition
)
from memory_manager import MemoryManager
from i18n import get_i18n
from config_manager import ConfigManager

logger = logging.getLogger("Brain")


class Brain:
    """The Director: ê²Œì„ íë¦„ í†µì œ"""
    
    def __init__(self, dev_mode: bool = False, provider: str = None, model_name: str = None, api_key: str = None, language: str = "en"):
        self.dev_mode = dev_mode
        self.language = language
        self.memory_manager = MemoryManager(
            dev_mode=dev_mode,
            provider=provider,
            model_name=model_name,
            api_key=api_key
        )
        self.state = CharacterState()
        self.history = DialogueHistory(max_turns=10)
        self.turns_since_image = 0
        # ì´ˆê¸° ì„¤ì • ì •ë³´
        self.initial_config: Optional[Dict] = None
        # ì‹œê°„ ì¸¡ì •ìš© ë³€ìˆ˜
        self._last_llm_time = 0.0
    
    def set_initial_config(self, config: Dict[str, Any]):
        """ì´ˆê¸° ì„¤ì • ì •ë³´ ì„¤ì •"""
        self.initial_config = config
        logger.info("Initial configuration set")
    
    def generate_response(self, player_input: str) -> Dict:
        """
        í”Œë ˆì´ì–´ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
        """
        # 1. Python ê¸°ë°˜ ê´€ê³„ ì „í™˜ ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ 1)
        transition_occurred, new_status = check_status_transition(self.state)
        if transition_occurred and new_status:
            logger.info(f"Status transition: {self.state.relationship_status} -> {new_status}")
            self.state.relationship_status = new_status
        
        # 2. LLM í˜¸ì¶œ (ì²« í„´ë„ í¬í•¨) - ë©”ì¸ ì‘ë‹µ ìƒì„±
        llm_response = self._call_llm(player_input)
        
        # Ollama ì›ë³¸ ì‘ë‹µ ë¡œê·¸ ì¶œë ¥ (dev_modeì¼ ë•Œë§Œ)
        if self.dev_mode:
            logger.info("=" * 80)
            logger.info("ğŸ“¥ [OLLAMA RAW RESPONSE]")
            logger.info("=" * 80)
            logger.info(llm_response)
            logger.info("=" * 80)
        
        # 3. JSON íŒŒì‹± ë° ê²€ì¦
        try:
            logger.debug(f"Starting JSON parsing. LLM response length: {len(llm_response)}")
            data = self._parse_json(llm_response)
            logger.debug(f"JSON parsing successful. Data keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
            self._validate_response(data)
            logger.debug("JSON validation successful")
            
            # íŒŒì‹± ë° ê²€ì¦ëœ JSON ë¡œê·¸ ì¶œë ¥ (dev_modeì¼ ë•Œë§Œ)
            if self.dev_mode:
                logger.info("=" * 80)
                logger.info("âœ… [PARSED JSON]")
                logger.info("=" * 80)
                import json as json_module
                logger.info(json_module.dumps(data, ensure_ascii=False, indent=2))
                logger.info("=" * 80)
        except Exception as e:
            import traceback
            logger.error(f"JSON parsing failed: {e}")
            logger.error(f"Error type: {type(e).__name__}")
            logger.error(f"LLM response (first 500 chars): {llm_response[:500]}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            return self._fallback_response(player_input)
        
        # 4. ê°€ì±  ì ìš©
        proposed_delta = data.get("proposed_delta", {})
        final_delta, gacha_tier, multiplier = apply_gacha_to_delta(proposed_delta)
        
        # 5. ë¸íƒ€ ì ìš© (íŠ¸ë¼ìš°ë§ˆ í˜ë„í‹° í¬í•¨)
        self.state.apply_delta(final_delta, trauma_penalty=True)
        
        # 6. ë±ƒì§€ ê²€ì‚¬
        new_badge = check_badge_conditions(self.state)
        if new_badge:
            self.state.add_badge(new_badge)
            logger.info(f"Badge acquired: {new_badge}")
        
        # 7. ë°°ê²½ ì—…ë°ì´íŠ¸ (LLMì´ ì œê³µí•œ ê²½ìš°)
        background = data.get("background", "")
        previous_background = self.state.current_background  # ë³€ê²½ ì „ ë°°ê²½ ì €ì¥
        background_changed = False
        
        if background:
            # backgroundê°€ í•œ ê¸€ìë¼ë„ ë°”ë€Œë©´ ë³€ê²½ìœ¼ë¡œ ê°„ì£¼
            if background != previous_background:
                background_changed = True
                self.state.current_background = background
                logger.info(f"Background updated: {previous_background} â†’ {background}")
            else:
                logger.debug(f"Background unchanged: {background}")
        else:
            # ë°°ê²½ì´ ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì´ì „ ë°°ê²½ ìœ ì§€
            background = self.state.current_background
            logger.debug(f"Background not provided, keeping previous: {background}")
        
        # 8. ì´ë¯¸ì§€ ìƒì„± í•„ìš” ì—¬ë¶€ íŒë‹¨
        visual_change = data.get("visual_change_detected", False)
        self.turns_since_image += 1
        
        # ì´ë¯¸ì§€ ìƒì„± ì´ìœ  ì¶”ì 
        image_generation_reasons = []
        
        # ë°°ê²½ ë³€ê²½ ì²´í¬ (í•œ ê¸€ìë¼ë„ ë°”ë€Œë©´ ê°•ì œë¡œ ì´ë¯¸ì§€ ìƒì„±)
        if background_changed:
            visual_change = True
            image_generation_reasons.append(f"ë°°ê²½ ë³€ê²½: {previous_background} â†’ {background}")
            logger.info(f"Background changed, forcing image generation")
        
        # LLMì´ ì§ì ‘ ìš”ì²­í•œ ê²½ìš°
        if data.get("visual_change_detected", False):
            reason = data.get("reason", "")
            if reason:
                image_generation_reasons.append(f"LLM ìš”ì²­: {reason}")
            else:
                image_generation_reasons.append("LLM ìš”ì²­: visual_change_detected=true")
        
        # ê°•ì œ ê°±ì‹  ì²´í¬ (5í„´ ê²½ê³¼)
        if self.turns_since_image >= config.IMAGE_GENERATION_TRIGGERS["force_refresh_turns"]:
            visual_change = True
            image_generation_reasons.append(f"ê°•ì œ ê°±ì‹ : {self.turns_since_image}í„´ ê²½ê³¼ (ìµœëŒ€ {config.IMAGE_GENERATION_TRIGGERS['force_refresh_turns']}í„´)")
        
        # ê°€ì±  í‹°ì–´ ì²´í¬
        if gacha_tier in config.IMAGE_GENERATION_TRIGGERS["critical_gacha_tiers"]:
            visual_change = True
            tier_name = {"jackpot": "ê·¹ì§„í•œ ë°˜ì‘", "surprise": "ë†€ë¼ìš´ ë°˜ì‘", "critical": "ê°•ë ¬í•œ ë°˜ì‘"}.get(gacha_tier, gacha_tier)
            image_generation_reasons.append(f"íŠ¹ìˆ˜ ë°˜ì‘: {tier_name} (ê°€ì±  í‹°ì–´: {gacha_tier})")
        
        # ê´€ê³„ ì „í™˜ ì²´í¬
        if transition_occurred and new_status in config.IMAGE_GENERATION_TRIGGERS["status_transitions"]:
            visual_change = True
            image_generation_reasons.append(f"ê´€ê³„ ì „í™˜: {self.state.relationship_status} â†’ {new_status}")
        
        # 9. íˆìŠ¤í† ë¦¬ ì¶”ê°€ (visual_promptì™€ background í¬í•¨)
        self.state.total_turns += 1
        try:
            logger.debug(f"Creating DialogueTurn. History type: {type(self.history)}, history.turns type: {type(self.history.turns) if hasattr(self.history, 'turns') else 'N/A'}")
            turn = DialogueTurn(
                turn_number=self.state.total_turns,
                player_input=player_input,
                character_speech=data.get("speech", ""),
                character_thought=data.get("thought", ""),
                emotion=data.get("emotion", "neutral"),
                visual_prompt=data.get("visual_prompt", ""),
                background=background
            )
            logger.debug(f"DialogueTurn created. Adding to history...")
            self.history.add(turn)
            logger.debug(f"Turn added successfully. History length: {len(self.history.turns)}")
        except Exception as e:
            import traceback
            logger.error(f"Failed to add turn to history: {e}")
            logger.error(f"Error type: {type(e).__name__}")
            logger.error(f"History type: {type(self.history)}")
            logger.error(f"History.turns type: {type(self.history.turns) if hasattr(self.history, 'turns') else 'N/A'}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            # íˆìŠ¤í† ë¦¬ ì¶”ê°€ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

        # 10. ì¥ê¸° ê¸°ì–µ ì—…ë°ì´íŠ¸ (10í„´ë§ˆë‹¤ í•œ ë²ˆ, ê¸°ì¡´ long_memory + ìµœê·¼ íˆìŠ¤í† ë¦¬ ê¸°ë°˜)
        try:
            self._update_long_memory_if_needed()
        except Exception as e:
            import traceback
            logger.error(f"Failed to update long-term memory: {e}")
            logger.error(traceback.format_exc())
        
        # 11. ì‘ë‹µ ì¡°ë¦½
        response = {
            "thought": data.get("thought", ""),
            "speech": data.get("speech", ""),
            "action_speech": data.get("action_speech", ""),  
            "emotion": data.get("emotion", "neutral"),
            "visual_change_detected": visual_change,
            "visual_prompt": data.get("visual_prompt", ""),
            "background": background,
            "reason": data.get("reason", ""),
            "image_generation_reasons": image_generation_reasons,  # ì´ë¯¸ì§€ ìƒì„± ì´ìœ  ëª©ë¡
            "final_delta": final_delta,
            "gacha_tier": gacha_tier,
            "multiplier": multiplier,
            "relationship_status": self.state.relationship_status,
            "mood": interpret_mood(self.state),
            "badges": self.state.badges.copy(),
            "stats": self.state.get_stats_dict(),
            "new_badge": new_badge
        }
        
        # LLM ë³´ê³  ê´€ê³„ ì „í™˜ ì²˜ë¦¬ (ìˆ˜ì¹˜ ì¡°ê±´ ê²€ì¦ í¬í•¨)
        if data.get("relationship_status_change", False):
            new_status_name = data.get("new_status_name", "")
            # ëª¨ë“  LLM íŒë‹¨ ìƒíƒœì— ëŒ€í•´ ìˆ˜ì¹˜ ì¡°ê±´ ê²€ì¦
            if new_status_name in ["Lover", "FiancÃ©e", "Partner", "Master", "Slave"]:
                current_status = self.state.relationship_status
                if validate_status_transition_condition(self.state, current_status, new_status_name):
                    self.state.relationship_status = new_status_name
                    response["relationship_status"] = new_status_name
                    logger.info(f"LLM reported status change: {new_status_name} (validated)")
                else:
                    logger.warning(f"LLM reported status change to {new_status_name}, but condition not met. Current stats: P={self.state.P:.1f}, A={self.state.A:.1f}, D={self.state.D:.1f}, I={self.state.I:.1f}, T={self.state.T:.1f}, Dep={self.state.Dep:.1f}")
        
        # ì´ë¯¸ì§€ ìƒì„± ì‹œ ì¹´ìš´í„° ë¦¬ì…‹
        if visual_change:
            self.turns_since_image = 0
        
        return response
    
    def _call_llm(self, player_input: str) -> str:
        """LLM í˜¸ì¶œ (Ollama API) - ë©”ì¸ ì‘ë‹µë§Œ ë°˜í™˜ (ì¥ê¸° ê¸°ì–µì€ ë³„ë„ ê°±ì‹ )"""
        result = self.memory_manager.get_model()
        if result is None:
            error_msg = (
                "Ollama APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                "í™•ì¸ ì‚¬í•­:\n"
                "1. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸ (ollama serve)\n"
                "2. config.pyì˜ OLLAMA_API_URLê³¼ OLLAMA_MODEL_NAME í™•ì¸\n"
                "3. ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ollama pull qwen2.5:14b)"
            )
            raise RuntimeError(error_msg)
        
        # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (ë©”ì¸ ì‘ë‹µìš©)
        prompt = self._build_prompt(player_input)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œê·¸ ì¶œë ¥ (dev_modeì¼ ë•Œë§Œ)
        if self.dev_mode:
            logger.info("=" * 80)
            logger.info("ğŸ“ [SYSTEM PROMPT]")
            logger.info("=" * 80)
            logger.info(prompt)
            logger.info("=" * 80)
        
        logger.info("Calling LLM API...")
        try:
            # LLM ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì‹œì‘
            import time
            llm_start_time = time.time()
            
            # Ollama API í˜¸ì¶œ (ë©”ì¸ ì‘ë‹µ)
            response_text = self.memory_manager.generate(
                prompt,
                temperature=config.LLM_CONFIG["temperature"],
                top_p=config.LLM_CONFIG["top_p"],
                max_tokens=config.LLM_CONFIG["max_tokens"]
            )
            
            # LLM ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì™„ë£Œ
            llm_elapsed_time = time.time() - llm_start_time
            logger.info(f"â±ï¸ LLM ì‘ë‹µ ì‹œê°„: {llm_elapsed_time:.2f}s")
            # ì‹œê°„ ì •ë³´ ì €ì¥ (ì „ì²´ ì™„ë£Œ ë¡œê·¸ì—ì„œ ì‚¬ìš©)
            self._last_llm_time = llm_elapsed_time
            
            if not response_text or not response_text.strip():
                raise ValueError("Ollama returned empty response")

            return response_text
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì‹œê°„ ì¸¡ì •
            import time
            if 'llm_start_time' in locals():
                llm_elapsed_time = time.time() - llm_start_time
                logger.error(f"â±ï¸ LLM ì‘ë‹µ ì‹œê°„ (ì—ëŸ¬): {llm_elapsed_time:.2f}s")
                self._last_llm_time = llm_elapsed_time
            logger.error(f"Ollama API call failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
        raise RuntimeError(f"Ollama API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    def _update_long_memory_if_needed(self):
        """
        ì¥ê¸° ê¸°ì–µ ì—…ë°ì´íŠ¸ (10í„´ë§ˆë‹¤ 1ë²ˆ)
        - ê¸°ì¡´ long_memory + ìµœê·¼ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì— 500ì ì´ë‚´ ìš”ì•½ì„ ìš”ì²­
        """
        # 10í„´ë§ˆë‹¤ë§Œ ê°±ì‹  (0í„´ì€ ì œì™¸)
        if self.state.total_turns <= 0 or self.state.total_turns % 10 != 0:
            return

        # ëª¨ë¸ í™•ì¸
        result = self.memory_manager.get_model()
        if result is None:
            logger.warning("long_memory ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
            return

        i18n = get_i18n()
        i18n.set_language(self.language)

        # ê¸°ì¡´ ì¥ê¸° ê¸°ì–µ (ì—†ìœ¼ë©´ ê¸°ë³¸ ë¬¸êµ¬)
        existing_memory = self.state.long_memory if self.state.long_memory else i18n.get_default("no_memory")

        # ìµœê·¼ íˆìŠ¤í† ë¦¬ (DialogueHistoryëŠ” ì´ë¯¸ max_turns=10ì´ë¯€ë¡œ, format_for_promptë¡œ ì¶©ë¶„)
        history_text = self.history.format_for_prompt()

        # ì¥ê¸° ê¸°ì–µ ìš”ì•½ ì „ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë‹¨ë¬¸ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ ìš”ì²­)
        if self.language == "kr":
            prompt = f"""{i18n.get_prompt("long_memory_update_title")}

{i18n.get_prompt("long_memory_update_instruction")}
{i18n.get_prompt("long_memory_update_focus")}
{i18n.get_prompt("long_memory_update_keep")}
{i18n.get_prompt("long_memory_update_combine")}

{i18n.get_prompt("long_memory_existing", existing_memory=existing_memory)}

{i18n.get_prompt("data_context_history")}
{history_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¤‘ìš”í•œ ê¸°ì–µë§Œ 500ì ì´í•˜ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ì´ë‚˜ ë‹¤ë¥¸ ë¶€ê°€ ì„¤ëª… ì—†ì´ ìš”ì•½ í…ìŠ¤íŠ¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        else:
            prompt = f"""{i18n.get_prompt("long_memory_update_title")}

{i18n.get_prompt("long_memory_update_instruction")}
{i18n.get_prompt("long_memory_update_focus")}
{i18n.get_prompt("long_memory_update_keep")}
{i18n.get_prompt("long_memory_update_combine")}

{i18n.get_prompt("long_memory_existing", existing_memory=existing_memory)}

{i18n.get_prompt("data_context_history")}
{history_text}

Based on the above, please summarize only important memories in 500 characters or less. Please write only the summary text without JSON format or additional explanations.
"""

        logger.info(f"ğŸ” Updating long-term memory (turn={self.state.total_turns})")

        try:
            response_text = self.memory_manager.generate(
                prompt,
                temperature=config.LLM_CONFIG["temperature"],
                top_p=config.LLM_CONFIG["top_p"],
                max_tokens=config.LLM_CONFIG["max_tokens"]
            )

            if not response_text or not response_text.strip():
                logger.warning("long_memory ì—…ë°ì´íŠ¸ LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
                return

            # ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (JSON íŒŒì‹± ì—†ì´)
            new_summary = response_text.strip()
            
            # JSON í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¤‘ê´„í˜¸ë‚˜ ë”°ì˜´í‘œ ë“± ì œê±° ì‹œë„
            # í•˜ì§€ë§Œ ìš°ì„  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
            if len(new_summary) > 500:
                # 500ìê¹Œì§€ë§Œ ì‚¬ìš© (ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ëŠì–´ì§€ì§€ ì•Šë„ë¡ ê³µë°±ì´ë‚˜ ë¬¸ì¥ ë¶€í˜¸ì—ì„œ ìë¦„)
                new_summary = new_summary[:500]
                last_period = new_summary.rfind('.')
                last_space = new_summary.rfind(' ')
                if last_period > 450:  # ë§ˆì§€ë§‰ 50ì ë‚´ì— ë§ˆì¹¨í‘œê°€ ìˆìœ¼ë©´
                    new_summary = new_summary[:last_period + 1]
                elif last_space > 450:  # ë§ˆì§€ë§‰ 50ì ë‚´ì— ê³µë°±ì´ ìˆìœ¼ë©´
                    new_summary = new_summary[:last_space]
            
            if new_summary:
                prev_len = len(self.state.long_memory) if self.state.long_memory else 0
                logger.info(f"ì¥ê¸° ê¸°ì–µ ê°±ì‹  ì™„ë£Œ (ì´ì „ ê¸¸ì´: {prev_len}, ìƒˆ ê¸¸ì´: {len(new_summary)}): {new_summary[:100]}...")
                self.state.long_memory = new_summary
            else:
                logger.warning("long_memory ì—…ë°ì´íŠ¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
        except Exception as e:
            logger.error(f"long_memory ì—…ë°ì´íŠ¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
    
    def _build_prompt(self, player_input: str) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (ë‹¤êµ­ì–´ ì§€ì›)"""
        # I18n ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        i18n = get_i18n()
        i18n.set_language(self.language)
        
        # ComfyUI ìŠ¤íƒ€ì¼ì— ë”°ë¼ visual_prompt ì¶œë ¥ í˜•ì‹ ë¶„ê¸°
        comfy_style = "QWEN/Z-image"
        try:
            cm = ConfigManager()
            env_cfg = cm.load_env_config()
            comfy_style = env_cfg.get("comfyui_settings", {}).get("style", "QWEN/Z-image")
        except Exception as e:
            logger.warning(f"Failed to load ComfyUI style for prompt building: {e}")
        visual_prompt_key = "output_visual_prompt_sdxl" if comfy_style == "SDXL" else "output_visual_prompt"
        
        mood = interpret_mood(self.state)
        intimacy_level = get_intimacy_level(self.state.I)
        trust_level = get_trust_level(self.state.T)
        dependency_level = get_dependency_level(self.state.Dep)
        
        # íŠ¸ë¼ìš°ë§ˆ ì§€ì¹¨ (player_nameì€ ë‚˜ì¤‘ì— ì¹˜í™˜)
        trauma_instruction_raw = get_trauma_instruction(self.state.trauma_level)
        
        # ê´€ê³„ ì „í™˜ ê°€ëŠ¥ì„± ì²´í¬
        status_check = self._get_status_transition_instruction()
        
        # íˆìŠ¤í† ë¦¬
        history_text = self.history.format_for_prompt()
        
        # ì¥ê¸° ê¸°ì–µ ì„¹ì…˜ (long_memoryê°€ ìˆìœ¼ë©´ í‘œì‹œ, ì²« í„´ì´ì–´ë„ ì‹œë‚˜ë¦¬ì˜¤ ë³µì› ì‹œ ì‚¬ìš©)
        long_memory_section = ""
        long_memory_instruction = ""
        logger.debug(f"Building prompt - total_turns: {self.state.total_turns}, long_memory exists: {bool(self.state.long_memory)}, long_memory length: {len(self.state.long_memory) if self.state.long_memory else 0}")
        if self.state.long_memory:
            # long_memoryê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ (ì‹œë‚˜ë¦¬ì˜¤ ë³µì› ì‹œì—ë„)
            long_memory_section = f"""
{i18n.get_prompt("long_memory_section")}
{self.state.long_memory}
"""
            logger.info(f"Long-term memory included in prompt (total_turns: {self.state.total_turns}): {self.state.long_memory[:100]}...")
            
            # ì¥ê¸° ê¸°ì–µ ì—…ë°ì´íŠ¸ ì§€ì‹œ ì¶”ê°€ (total_turns > 0ì´ê³  history.turnsê°€ ìˆìœ¼ë©´)
            if self.state.total_turns > 0 and self.history.turns:
                existing_memory = self.state.long_memory if self.state.long_memory else i18n.get_default("no_memory")
                long_memory_instruction = f"""
{i18n.get_prompt("long_memory_update_title")}

{i18n.get_prompt("long_memory_update_instruction")}
{i18n.get_prompt("long_memory_update_focus")}
{i18n.get_prompt("long_memory_update_keep")}
{i18n.get_prompt("long_memory_update_combine")}

{i18n.get_prompt("long_memory_existing", existing_memory=existing_memory)}
"""
        
        # í˜„ì¬ ë°°ê²½ ì •ë³´
        current_background = self.state.current_background
        
        # ë±ƒì§€ ì§€ì¹¨
        badge_behavior = ""
        if self.state.badges:
            # badgesê°€ setì¸ì§€ listì¸ì§€ í™•ì¸
            if isinstance(self.state.badges, set):
                # setì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ì„ì˜ì˜ ìš”ì†Œ ì„ íƒ
                badges_list = list(self.state.badges)
                active_badge = badges_list[-1] if badges_list else None
            else:
                # listì¸ ê²½ìš°
                active_badge = self.state.badges[-1]  # ê°€ì¥ ìµœê·¼ ë±ƒì§€
            
            if active_badge:
                badge_behavior = config.BADGE_BEHAVIORS.get(active_badge, "")
                if badge_behavior:
                    logger.debug(f"[BADGE] Active badge: {active_badge}, behavior length: {len(badge_behavior)}")
                else:
                    logger.warning(f"[BADGE] Badge '{active_badge}' found but no behavior defined in config.BADGE_BEHAVIORS")
        
        # Mood ì§€ì¹¨
        mood_behavior = ""
        current_mood = interpret_mood(self.state)
        mood_behavior = config.MOOD_BEHAVIORS.get(current_mood, "")
        if mood_behavior:
            logger.debug(f"[MOOD] Current mood: {current_mood}, behavior length: {len(mood_behavior)}")
        else:
            logger.warning(f"[MOOD] Mood '{current_mood}' found but no behavior defined in config.MOOD_BEHAVIORS")
        
        # ì£¼ì¸ê³µ ì •ë³´ ì¶”ì¶œ (ì´ˆê¸° ì„¤ì •ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        player_name = i18n.get_default("player_name")
        player_gender = i18n.get_default("player_gender")
        if self.initial_config:
            player_info = self.initial_config.get("player", {})
            player_name = player_info.get("name", i18n.get_default("player_name"))
            player_gender = player_info.get("gender", i18n.get_default("player_gender"))
        
        # íŠ¸ë¼ìš°ë§ˆ ì§€ì¹¨ì— player_name ì¹˜í™˜
        trauma_instruction = trauma_instruction_raw.replace("{player_name}", player_name) if trauma_instruction_raw else ""
        
        # ì´ˆê¸° ì„¤ì • ì •ë³´
        initial_context_section = ""
        character_profile_section = ""
        
        # ì´ˆê¸° ì„¤ì •ì—ì„œ ìºë¦­í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ëª¨ë“  í„´ì—ì„œ ì‚¬ìš©)
        if self.initial_config:
            char_info = self.initial_config.get("character", {})
            char_name = char_info.get("name", i18n.get_default("character_name"))
            char_age = char_info.get("age", 21)
            char_gender = char_info.get("gender", i18n.get_default("character_gender"))
            appearance = char_info.get("appearance", "")
            personality = char_info.get("personality", "")
            speech_style = char_info.get("speech_style", i18n.get_default("character_speech_style"))
            initial_context = self.initial_config.get("initial_context", "")
        else:
            # ê¸°ë³¸ê°’ (ì´ˆê¸° ì„¤ì •ì´ ì—†ì„ ë•Œ)
            char_name = i18n.get_default("character_name")
            char_age = 21
            char_gender = i18n.get_default("character_gender")
            appearance = ""
            personality = ""
            speech_style = i18n.get_default("character_speech_style")
            initial_context = ""
        
        # ìºë¦­í„° í”„ë¡œí•„ ì„¹ì…˜ (ëª¨ë“  í„´ì—ì„œ ì´ˆê¸° ì„¤ì •ì˜ ë‚˜ì´ í¬í•¨)
        if self.language == "kr":
            character_profile_section = f"""{i18n.get_prompt("character_profile_title")}
{i18n.get_prompt("character_name", char_name=char_name, char_age=char_age, char_gender=char_gender)}
{i18n.get_prompt("character_opponent", player_name=player_name, player_gender=player_gender)}"""
        else:
            character_profile_section = f"""{i18n.get_prompt("character_profile_title")}
{i18n.get_prompt("character_name", char_name=char_name, char_age=char_age, char_gender=char_gender)}
{i18n.get_prompt("character_opponent", player_name=player_name, player_gender=player_gender)}"""
        
        if appearance:
            character_profile_section += f"\n{i18n.get_prompt('character_appearance', appearance=appearance)}"
        if personality:
            character_profile_section += f"\n{i18n.get_prompt('character_personality', personality=personality)}"
        if speech_style:
            character_profile_section += f"\n{i18n.get_prompt('character_speech_style_custom', speech_style=speech_style)}"
        character_profile_section += f"\n{i18n.get_prompt('character_language')}"
        
        # íŠ¸ë¼ìš°ë§ˆ ì§€ì¹¨ ì„¹ì…˜ êµ¬ì„±
        trauma_section = ""
        if trauma_instruction:
            trauma_section = f"""
{trauma_instruction}
"""
        
        # íŠ¹ìˆ˜ ëª…ë ¹ ì„¹ì…˜ êµ¬ì„± (íŠ¸ë¼ìš°ë§ˆ ì œì™¸)
        special_commands = []
        if mood_behavior:
            special_commands.append(mood_behavior)
        if badge_behavior:
            special_commands.append(badge_behavior)
        if status_check:
            special_commands.append(status_check)
        
        # íŠ¹ìˆ˜ ëª…ë ¹ í…ìŠ¤íŠ¸ (ì–¸ì–´ë³„)
        if self.language == "kr":
            special_commands_text = " / ".join(special_commands) if special_commands else "[ì—†ìŒ]"
        else:
            special_commands_text = " / ".join(special_commands) if special_commands else "[None]"
        
        # íŠ¸ë¼ìš°ë§ˆ ë ˆë²¨ ì´ë¦„
        trauma_level_name = config.TRAUMA_LEVELS.get(round(self.state.trauma_level * 4) / 4, "Unknown")
        
        # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
        prompt = f"""{i18n.get_prompt("system_intro")}
{i18n.get_prompt("system_json_only")}
{i18n.get_prompt("system_no_censorship")}
{i18n.get_prompt("system_language")}

{character_profile_section}


{i18n.get_prompt("state_definition_title")}

{i18n.get_prompt("state_pleasure")}
{i18n.get_prompt("state_arousal")}
{i18n.get_prompt("state_dominance")}
{i18n.get_prompt("state_intimacy")}
{i18n.get_prompt("state_trust", player_name=player_name)}
{i18n.get_prompt("state_dependency", player_name=player_name)}
{i18n.get_prompt("state_delta_instruction")}
{i18n.get_prompt("state_delta_range")}
{i18n.get_prompt("state_dominance_guidance")}

{i18n.get_prompt("behavior_priority_title")}

{i18n.get_prompt("behavior_priority_1", player_name=player_name, player_input=player_input)}
{i18n.get_prompt("behavior_priority_2")}
{i18n.get_prompt("behavior_quality_1")}
{i18n.get_prompt("behavior_quality_2", player_input=player_input)}
{i18n.get_prompt("behavior_quality_3")}
{i18n.get_prompt("behavior_quality_4", player_name=player_name)}
{i18n.get_prompt("background_consistency_1")}
{i18n.get_prompt("background_consistency_2", current_background=current_background)}
{i18n.get_prompt("background_consistency_3", player_name=player_name)}
{i18n.get_prompt("background_consistency_4")}
{i18n.get_prompt("background_consistency_5")}
{i18n.get_prompt("visual_change_1")}
{i18n.get_prompt("visual_change_2")}
{i18n.get_prompt("visual_change_3")}
{i18n.get_prompt("visual_change_4")}
{trauma_section}{i18n.get_prompt("data_context_title")}
{i18n.get_prompt("data_context_psychology", mood=mood, relationship_status=self.state.relationship_status)}
{i18n.get_prompt("data_context_stats", P=self.state.P, A=self.state.A, D=self.state.D, I=self.state.I, T=self.state.T, Dep=self.state.Dep)}
{i18n.get_prompt("data_context_accumulated", intimacy_level=intimacy_level, trust_level=trust_level, dependency_level=dependency_level)}
{i18n.get_prompt("data_context_trauma", trauma_level=self.state.trauma_level, trauma_level_name=trauma_level_name)}
{i18n.get_prompt("data_context_special", special_commands_text=special_commands_text)}
{i18n.get_prompt("data_context_history")}
{history_text}

{i18n.get_prompt("output_format_title")}

{i18n.get_prompt("output_format_json")}

```
{{
{i18n.get_prompt("output_thought")},
{i18n.get_prompt("output_speech")},
{i18n.get_prompt("output_action_speech")},
{i18n.get_prompt("output_emotion")},
{i18n.get_prompt("output_visual_change")},
{i18n.get_prompt(visual_prompt_key)},
{i18n.get_prompt("output_background")},
{i18n.get_prompt("output_reason")},
{i18n.get_prompt("output_delta")},
{i18n.get_prompt("output_relationship_change")},
{i18n.get_prompt("output_new_status")}
}}
``` 
{long_memory_section}
{self._get_initial_context_before_input(player_name, initial_context, i18n)}
{i18n.get_prompt("player_input_label", player_name=player_name, player_input=player_input)}
{i18n.get_prompt("player_input_instruction")}
{i18n.get_prompt("player_input_json")}
"""
        
        # ë””ë²„ê¹…: long_memory_sectionì´ ì‹¤ì œë¡œ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if self.state.long_memory and not long_memory_section:
            logger.error(f"âš ï¸ Warning: long_memory exists but long_memory_section is empty! (total_turns: {self.state.total_turns})")
        elif long_memory_section:
            logger.debug(f"âœ… long_memory_section included in prompt (length: {len(long_memory_section)})")
        
        return prompt
    
    def _get_first_dialogue_emphasis(self, i18n) -> str:
        """ì²˜ìŒ 10í„´ ë™ì•ˆ ì´ˆê¸° ìƒí™© ì„¤ëª…ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ëŠ” ì§€ì‹œì‚¬í•­"""
        if self.state.total_turns >= 10:
            return ""
        
        return f"""
{i18n.get_prompt("initial_situation_emphasis")}
"""
    
    def _get_initial_context_before_input(self, player_name: str, initial_context: str, i18n) -> str:
        """ì²˜ìŒ 10í„´ ë™ì•ˆ player_input ìœ„ì— ì´ˆê¸° ëŒ€í™” ì„¸íŒ…ê³¼ emphasis ì¶”ê°€"""
        if self.state.total_turns >= 10 or not initial_context:
            return ""
        
        emphasis = self._get_first_dialogue_emphasis(i18n)
        return f"""
{i18n.get_prompt("initial_situation_title")}
{initial_context}
{i18n.get_prompt("initial_situation_instruction", player_name=player_name)}{emphasis}
"""
    
    def _get_status_transition_instruction(self) -> str:
        """í˜„ì¬ ìƒíƒœì—ì„œ ê°€ëŠ¥í•œ ë‹¤ìŒ ìƒíƒœ ì „í™˜ ì§€ì¹¨"""
        current = self.state.relationship_status
        transitions = config.STATUS_TRANSITIONS.get(current, {})
        possible_next = transitions.get("to", [])
        
        if not possible_next:
            return ""
        
        # LLM ë³´ê³ ê°€ í•„ìš”í•œ ìƒíƒœë§Œ í•„í„°ë§: Lover, FiancÃ©e, Partner, Master, Slave
        llm_states = [s for s in possible_next if s in ["Lover", "FiancÃ©e", "Partner", "Master", "Slave"]]
        
        if not llm_states:
            return ""
        
        i18n = get_i18n()
        i18n.set_language(self.language)
        
        # ì—¬ëŸ¬ ìƒíƒœë¡œ ê°ˆ ìˆ˜ ìˆì„ ë•Œ ëª…í™•í•˜ê²Œ ë‚˜ì—´
        states_str = ', '.join(llm_states)
        instruction = f"{i18n.get_prompt('status_transition_rule_title')} {i18n.get_prompt('status_transition_current_state', current=current, states=states_str)}"
        instruction += i18n.get_prompt("status_transition_select_one")
        
        # ê° ìƒíƒœë³„ ì¡°ê±´ê³¼ í‚¤ì›Œë“œ ë‚˜ì—´
        state_descriptions = []
        for state in llm_states:
            if state == "Lover":
                state_descriptions.append(i18n.get_prompt("status_transition_lover_desc"))
            elif state == "FiancÃ©e":
                state_descriptions.append(i18n.get_prompt("status_transition_fiancee_desc"))
            elif state == "Partner":
                state_descriptions.append(i18n.get_prompt("status_transition_partner_desc"))
            elif state == "Master":
                state_descriptions.append(i18n.get_prompt("status_transition_master_desc"))
            elif state == "Slave":
                state_descriptions.append(i18n.get_prompt("status_transition_slave_desc"))
        
        instruction += "\n".join(state_descriptions)
        instruction += i18n.get_prompt("status_transition_instruction")
        
        return instruction
    
    def _parse_json(self, text: str) -> Dict:
        """LLM ì¶œë ¥ì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±"""
        
        # ==========================================================
        # 1. ì›ë³¸ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: BOM ë° ëª¨ë“  ìœ ë‹ˆì½”ë“œ ê³µë°± ë¬¸ì ì œê±°
        # ==========================================================
        
        # 1-a. ì½”ë“œë¸”ë¡ ë§ˆí¬ë‹¤ìš´ ì œê±° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        text = re.sub(r'```json\s*', '', text, flags=re.IGNORECASE | re.MULTILINE)
        text = re.sub(r'```\s*', '', text, flags=re.MULTILINE)
        
        # 1-b. UTF-8 BOM ë¬¸ì ì œê±° (U+FEFF)
        BOM_CHAR = '\ufeff'
        text = text.lstrip(BOM_CHAR)
        
        # 1-c. ëª¨ë“  ì¢…ë¥˜ì˜ ê³µë°± ë¬¸ì(ì¤„ë°”ê¿ˆ, íƒ­, U+00A0 ë“±)ë¥¼ ì œê±°í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
        # - re.sub(r'\s', '', ...)ëŠ” ëª¨ë“  ê³µë°±ì„ ì œê±°í•˜ë¯€ë¡œ, JSON ë‚´ë¶€ì˜ ê³µë°±ì´ ì‚¬ë¼ì ¸ì„œëŠ” ì•ˆ ë¨.
        # - ë”°ë¼ì„œ, strip()ìœ¼ë¡œ ì‹œì‘/ë ê³µë°±ë§Œ ì œê±°í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
        # - í•˜ì§€ë§Œ, char 2 ì˜¤ë¥˜ëŠ” ì‹œì‘ ë¶€ë¶„ì˜ ìˆ¨ê²¨ì§„ ê³µë°±ì´ë¯€ë¡œ, ì‹œì‘ ë¶€ë¶„ë§Œ ê°•ë ¥í•˜ê²Œ ì œê±°í•©ë‹ˆë‹¤.
        text = text.lstrip()
        
        # 1-d. JSON íŒŒì‹± ì „ ì „ì²˜ë¦¬: + ê¸°í˜¸ ì œê±° (JSONì—ì„œëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ í˜•ì‹)
        text = re.sub(r'":\s*\+(\d+)', r'": \1', text)
        
        # ==========================================================
        # 2. ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ ìœ íš¨ JSON ì¶”ì¶œ (ìˆ˜ì •: ì›ë³¸ í…ìŠ¤íŠ¸ ì •ì œ í›„ ì‹œì‘)
        # ==========================================================
        
        depth = 0
        start = None
        
        # ëª¨ë“  ì „ì²˜ë¦¬ë¥¼ ë§ˆì¹œ í…ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.
        for i, ch in enumerate(text):
            if ch == '{':
                if depth == 0:
                    # ì²« ë²ˆì§¸ ìœ íš¨í•œ '{'ë¥¼ ì°¾ì•˜ì„ ë•Œ ì‹œì‘ ì¸ë±ìŠ¤ ì„¤ì •
                    start = i
                depth += 1
            elif ch == '}':
                depth -= 1
                
                if depth == 0 and start is not None:
                    # ìœ íš¨í•œ ìµœìƒìœ„ JSON ê°ì²´ì˜ ëì„ ì°¾ì•˜ì„ ë•Œ
                    candidate = text[start:i+1]
                    
                    # ë””ë²„ê¹…: íŒŒì‹± ì‹œë„ ì „í›„ ë¡œê·¸
                    logger.debug(f"JSON íŒŒì‹± ì‹œë„ ì¤‘... (ê¸¸ì´: {len(candidate)}ì)")
                    
                    try:
                        parsed = json.loads(candidate)
                        logger.debug("JSON íŒŒì‹± ì„±ê³µ!")
                        return parsed
                    except json.JSONDecodeError as e:
                        logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        logger.warning(f"ì˜¤ë¥˜ ìœ„ì¹˜: ë¬¸ì {e.pos}ë²ˆì§¸")
                        
                        # ì˜¤ë¥˜ê°€ ë‚¬ìœ¼ë¯€ë¡œ, ë‹¤ìŒ ì¤‘ê´„í˜¸ ìŒì„ ê³„ì† ì°¾ìŠµë‹ˆë‹¤.
                        start = None  # ë‹¤ìŒ '{'ë¥¼ ì°¾ê¸° ìœ„í•´ startë¥¼ ë¦¬ì…‹
                        depth = 0
                        continue

        # ==========================================================
        # 3. JSONì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì˜¤ë¥˜ ë¡œê¹…
        # ==========================================================
        
        logger.error("JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 500ì): {text[:500]}")
        raise ValueError("No valid JSON found")

    def _validate_response(self, data: Dict):
        """ì‘ë‹µ ìœ íš¨ì„± ê²€ì¦"""
        required = ["thought", "speech", "emotion", "proposed_delta"]
        missing = [k for k in required if k not in data]
        if missing:
            raise ValueError(f"Missing required fields: {missing}")

        # proposed_delta ê²€ì¦ ë° ì •ê·œí™”
        proposed_delta = data.get("proposed_delta", {})
        if not isinstance(proposed_delta, dict):
            raise ValueError(f"proposed_delta must be a dict, got {type(proposed_delta)}")
        
        # delta ê°’ë“¤ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ê³  ë²”ìœ„ ì œí•œ (-10 ~ +10)
        normalized_delta = {}
        for key in ["P", "A", "D", "I", "T", "Dep"]:
            value = proposed_delta.get(key, 0)
            original_value = value  # ë””ë²„ê¹…ìš©
            
            # ë¬¸ìì—´ì¸ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
            if isinstance(value, str):
                # + ê¸°í˜¸ë§Œ ì œê±° (ìŒìˆ˜ëŠ” - ê¸°í˜¸ê°€ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨)
                # ì˜ˆ: "+5" â†’ "5" (ì–‘ìˆ˜), "-3" â†’ "-3" (ìŒìˆ˜, ë³€í™” ì—†ìŒ)
                value = value.replace("+", "").strip()
                try:
                    value = int(value)  # int()ëŠ” "-3"ì„ ìŒìˆ˜ -3ìœ¼ë¡œ ì •ìƒ ë³€í™˜
                except ValueError:
                    logger.warning(f"proposed_delta.{key}ë¥¼ ìˆ«ìë¡œ ë³€í™˜ ì‹¤íŒ¨: {original_value}, 0ìœ¼ë¡œ ì„¤ì •")
                    value = 0
            elif not isinstance(value, (int, float)):
                logger.warning(f"proposed_delta.{key}ê°€ ìˆ«ìê°€ ì•„ë‹˜: {original_value}, 0ìœ¼ë¡œ ì„¤ì •")
                value = 0
            else:
                value = int(value)
            
            # ë²”ìœ„ ì œí•œ (-10 ~ +10)
            value = max(-10, min(10, value))
            normalized_delta[key] = value
            
            # ë””ë²„ê¹…: ê°’ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if original_value != value and isinstance(original_value, (int, float, str)):
                logger.debug(f"proposed_delta.{key}: {original_value} â†’ {value} (ì •ê·œí™”ë¨)")
        
        data["proposed_delta"] = normalized_delta

    def _fallback_response(self, player_input: str) -> Dict:
        """íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
        i18n = get_i18n()
        i18n.set_language(self.language)
        
        return {
            "thought": i18n.get_prompt("fallback_thought"),
            "speech": i18n.get_prompt("fallback_speech"),
            "emotion": "nervous",
            "visual_change_detected": False,
            "visual_prompt": "",
            "background": self.state.current_background,
            "reason": "",
            "final_delta": {},
            "gacha_tier": "normal",
            "multiplier": 1.0,
            "relationship_status": self.state.relationship_status,
            "mood": interpret_mood(self.state),
            "badges": self.state.badges.copy(),
            "stats": self.state.get_stats_dict(),
            "new_badge": None
        }
    
    def get_state(self) -> CharacterState:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return self.state
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.memory_manager.unload_model()

