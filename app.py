"""
Zeniji Emotion Simul - Main Application
Gradio UI ë° ê²Œì„ ë£¨í”„
"""

import gradio as gr
import logging
import argparse
import json
import os
from pathlib import Path
from typing import Tuple, Optional, Dict
from brain import Brain
from state_manager import CharacterState
from comfy_client import ComfyClient
from memory_manager import MemoryManager
from PIL import Image
import io
import config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("App")

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_FILE = Path("character_config.json")
API_KEY_DIR = Path("apikey")
OPENROUTER_API_KEY_FILE = API_KEY_DIR / "openrouter_api_key.txt"

# í”„ë¦¬ì…‹ ì •ì˜
PRESETS = {
    "ì†Œê¿‰ì¹œêµ¬": {
        "P": 60.0, "A": 50.0, "D": 45.0, "I": 70.0, "T": 70.0, "Dep": 30.0,
        "appearance": "korean beauty, friendly face, warm expression, casual clothes, childhood friend",
        "personality": "ë°ê³  í™œë°œí•˜ë©°, ì˜¤ëœ ì¹œêµ¬ë¼ì„œ í¸í•˜ê²Œ ëŒ€í™”í•¨. ë•Œë¡œëŠ” ì¥ë‚œìŠ¤ëŸ½ì§€ë§Œ ì§„ì‹¬ì´ ë‹´ê²¨ìˆìŒ."
    },
    "í˜ê´€ ë¼ì´ë²Œ": {
        "P": 20.0, "A": 70.0, "D": 80.0, "I": 10.0, "T": 10.0, "Dep": 0.0,
        "appearance": "korean beauty, sharp eyes, confident expression, competitive look, strong presence",
        "personality": "í•­ìƒ ê²½ìŸí•˜ê³  ì‹¶ì–´í•˜ë©°, ë‹¹ì‹ ì„ ë¼ì´ë²Œë¡œ ì¸ì‹. ë„ì „ì ì´ê³  ìì¡´ì‹¬ì´ ê°•í•¨."
    },
    "í”¼í/ì§‘ì°©": {
        "P": 30.0, "A": 80.0, "D": 20.0, "I": 90.0, "T": 20.0, "Dep": 90.0,
        "appearance": "korean beauty, tired eyes, intense gaze, unstable expression, obsessive look",
        "personality": "ë‹¹ì‹ ì—ê²Œ ê°•í•˜ê²Œ ì§‘ì°©í•˜ë©°, ë–¨ì–´ì§€ë©´ ë¶ˆì•ˆí•´í•¨. ê°ì • ê¸°ë³µì´ ì‹¬í•˜ê³  ì˜ì¡´ì ."
    }
}


class GameApp:
    """ê²Œì„ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, dev_mode: bool = False):
        self.dev_mode = dev_mode
        self.brain = None
        self.model_loaded = False
        self.current_image: Optional[Image.Image] = None  # PIL Image ì €ì¥
        self.comfy_client = None
    
    def load_config(self) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ - None ê°’ ì •ë¦¬"""
        if CONFIG_FILE.exists():
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # None ê°’ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                    return self._sanitize_config(config)
            except Exception as e:
                logger.warning(f"Failed to load config: {e}")
        return self._default_config()
    
    def _sanitize_config(self, config: Dict) -> Dict:
        """ì„¤ì •ì—ì„œ None ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´"""
        default = self._default_config()
        
        # initial_statsì˜ None ê°’ ì²˜ë¦¬
        initial_stats = config.get("initial_stats", {}) or {}
        sanitized_stats = {}
        for key in ["P", "A", "D", "I", "T", "Dep"]:
            val = initial_stats.get(key)
            if val is None:
                val = default["initial_stats"][key]
            sanitized_stats[key] = float(val) if val is not None else default["initial_stats"][key]
        
        # characterì˜ age ì²˜ë¦¬
        character = config.get("character", {}) or {}
        char_age = character.get("age")
        if char_age is None:
            char_age = default["character"]["age"]
        
        # None ê°’ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³‘í•©
        result = default.copy()
        result.update(config)
        result["initial_stats"] = sanitized_stats
        if "character" in result:
            result["character"]["age"] = int(char_age) if char_age is not None else default["character"]["age"]
        
        return result
    
    def _load_openrouter_api_key(self) -> str:
        """OpenRouter API í‚¤ë¥¼ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            if OPENROUTER_API_KEY_FILE.exists():
                with open(OPENROUTER_API_KEY_FILE, 'r', encoding='utf-8') as f:
                    api_key = f.read().strip()
                    return api_key if api_key else ""
            return ""
        except Exception as e:
            logger.warning(f"Failed to load OpenRouter API key: {e}")
            return ""
    
    def _save_openrouter_api_key(self, api_key: str) -> bool:
        """OpenRouter API í‚¤ë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            # apikey ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            API_KEY_DIR.mkdir(exist_ok=True)
            
            # API í‚¤ ì €ì¥
            with open(OPENROUTER_API_KEY_FILE, 'w', encoding='utf-8') as f:
                f.write(api_key.strip())
            
            logger.info(f"OpenRouter API key saved to {OPENROUTER_API_KEY_FILE}")
            return True
        except Exception as e:
            logger.error(f"Failed to save OpenRouter API key: {e}")
            return False
    
    def _default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "player": {
                "name": "",
                "gender": "ë‚¨ì„±"
            },
            "character": {
                "name": "ì˜ˆë‚˜",
                "age": 21,
                "gender": "ì—¬ì„±",
                "appearance": "korean beauty, short hair, brown eyes, cute face, casual outfit",
                "personality": "ë°ê³  í™œë°œí•˜ì§€ë§Œ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ ì•ì—ì„œëŠ” ìˆ˜ì¤ìŒì´ ë§ìŒ"
            },
            "initial_stats": {
                "P": 50.0,
                "A": 40.0,
                "D": 40.0,
                "I": 20.0,
                "T": 50.0,
                "Dep": 0.0
            },
            "initial_context": "",
            "initial_background": "college library table, evening light",
            "llm_settings": {
                "provider": "ollama",
                "ollama_model": "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                "openrouter_model": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
            }
        }
    
    def save_config(self, config_data: Dict) -> bool:
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Config saved to {CONFIG_FILE}")
            return True
        except Exception as e:
            logger.error(f"Failed to save config: {e}")
            return False
    
    def apply_preset(self, preset_name: str) -> Tuple[float, float, float, float, float, float, str, str]:
        """í”„ë¦¬ì…‹ ì ìš© - ëª¨ë“  ìˆ˜ì¹˜ê°€ í™•ì‹¤íˆ ìˆ«ìê°€ ë˜ë„ë¡ ë³´ì¥"""
        preset = PRESETS.get(preset_name, {})
        # get(key, default)ë¥¼ ì¨ë„ ë˜ì§€ë§Œ, í˜¹ì‹œ Noneì´ ë“¤ì–´ìˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ or ì²˜ë¦¬
        return (
            float(preset.get("P") or 50.0),
            float(preset.get("A") or 40.0),
            float(preset.get("D") or 40.0),
            float(preset.get("I") or 20.0),
            float(preset.get("T") or 50.0),
            float(preset.get("Dep") or 0.0),
            str(preset.get("appearance") or ""),
            str(preset.get("personality") or "")
        )
    
    def validate_and_start(
        self,
        player_name, player_gender,
        char_name, char_age, char_gender,
        appearance, personality,
        p_val, a_val, d_val, i_val, t_val, dep_val,
        initial_context, initial_background
    ) -> Tuple[str, str, list, str, str, str, str, str, str]:
        """ì„¤ì • ê²€ì¦ ë° ì‹œì‘ (ì²« ëŒ€í™” ìë™ ìƒì„±)"""
        # Slider ê°’ë“¤ì´ Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        p_val = p_val if p_val is not None else 50.0
        a_val = a_val if a_val is not None else 40.0
        d_val = d_val if d_val is not None else 40.0
        i_val = i_val if i_val is not None else 20.0
        t_val = t_val if t_val is not None else 50.0
        dep_val = dep_val if dep_val is not None else 0.0
        char_age = char_age if char_age is not None else 21
        
        # ìµœëŒ€ê°’ ê²€ì¦ (70 ì œí•œ)
        max_val = 70.0
        stats = {"P": p_val, "A": a_val, "D": d_val, "I": i_val, "T": t_val, "Dep": dep_val}
        exceeded = [k for k, v in stats.items() if v > max_val]
        
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        empty_result = (
            "âš ï¸ ê²½ê³ : ë‹¤ìŒ ìˆ˜ì¹˜ê°€ 70ì„ ì´ˆê³¼í•©ë‹ˆë‹¤: " + ", ".join(exceeded) if exceeded else "âŒ ì˜¤ë¥˜ ë°œìƒ",
            gr.Tabs(selected=None),
            [], "", "", None, "", "", ""
        )
        
        if exceeded:
            return empty_result
        
        # ì„¤ì • ë°ì´í„° êµ¬ì„±
        config_data = {
            "player": {
                "name": player_name or "",
                "gender": player_gender or "ë‚¨ì„±"
            },
            "character": {
                "name": char_name or "ì˜ˆë‚˜",
                "age": int(char_age) if char_age else 21,
                "gender": char_gender or "ì—¬ì„±",
                "appearance": appearance or "",
                "personality": personality or ""
            },
            "initial_stats": {
                "P": float(p_val),
                "A": float(a_val),
                "D": float(d_val),
                "I": float(i_val),
                "T": float(t_val),
                "Dep": float(dep_val)
            },
            "initial_context": initial_context or "",
            "initial_background": initial_background or "college library table, evening light"
        }
        
        # OpenRouter API í‚¤ ì²´í¬ ë° ìš°ì„  ì‚¬ìš© ì„¤ì •
        openrouter_api_key = self._load_openrouter_api_key()
        if openrouter_api_key and openrouter_api_key.strip():
            # OpenRouter API í‚¤ê°€ ìˆìœ¼ë©´ OpenRouterë¥¼ ìš°ì„  ì‚¬ìš©
            logger.info("OpenRouter API í‚¤ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. OpenRouterë¥¼ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.")
            if "llm_settings" not in config_data:
                config_data["llm_settings"] = {}
            config_data["llm_settings"]["provider"] = "openrouter"
            # OpenRouter ëª¨ë¸ì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if "openrouter_model" not in config_data["llm_settings"]:
                config_data["llm_settings"]["openrouter_model"] = "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
        else:
            # OpenRouter API í‚¤ê°€ ì—†ìœ¼ë©´ Ollama ì‚¬ìš©
            logger.info("OpenRouter API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Ollamaë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            if "llm_settings" not in config_data:
                config_data["llm_settings"] = {}
            config_data["llm_settings"]["provider"] = "ollama"
            # Ollama ëª¨ë¸ì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if "ollama_model" not in config_data["llm_settings"]:
                config_data["llm_settings"]["ollama_model"] = "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest"
        
        # ì €ì¥ (LLM ì„¤ì • í¬í•¨)
        if not self.save_config(config_data):
            return ("âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨", gr.Tabs(selected=None), [], "", "", None, "", "", "")
        
        # ëª¨ë¸ ë¡œë“œ
        status_msg, success = self.load_model()
        if not success:
            return (f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status_msg}", gr.Tabs(selected=None), [], "", "", None, "", "", "")
        
        # Brain ì´ˆê¸°í™” ë° ì„¤ì • ì ìš©
        try:
            # LLM ì„¤ì • ì½ê¸° (ì €ì¥ëœ ì„¤ì •ì—ì„œ)
            llm_settings = config_data.get("llm_settings", {})
            provider = llm_settings.get("provider", "ollama")
            ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
            openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
            # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ì´ë¯¸ ìœ„ì—ì„œ ë¡œë“œí–ˆì§€ë§Œ ë‹¤ì‹œ í™•ì¸)
            if provider == "openrouter":
                openrouter_api_key = self._load_openrouter_api_key()
            else:
                openrouter_api_key = ""
            
            if self.brain is None:
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain = Brain(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            
            # ì´ˆê¸° ì„¤ì • ì •ë³´ ì „ë‹¬
            self.brain.set_initial_config(config_data)
            
            # ì´ˆê¸° ìƒíƒœ ì ìš©
            self.brain.state.P = config_data["initial_stats"]["P"]
            self.brain.state.A = config_data["initial_stats"]["A"]
            self.brain.state.D = config_data["initial_stats"]["D"]
            self.brain.state.I = config_data["initial_stats"]["I"]
            self.brain.state.T = config_data["initial_stats"]["T"]
            self.brain.state.Dep = config_data["initial_stats"]["Dep"]
            self.brain.state.current_background = config_data["initial_background"]
            self.brain.state.clamp()
            
            logger.info("Initial configuration applied to Brain")
        except Exception as e:
            logger.error(f"Failed to apply config: {e}")
            return (f"âŒ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected=None), [], "", "", None, "", "", "")
        
        # ì²« ëŒ€í™” ìë™ ìƒì„±
        try:
            logger.info("Generating first dialogue automatically...")
            history, output_text, stats_text, image, choices_text, thought_text, action_text = self.process_turn("ëŒ€í™” ì‹œì‘", [])
            
            # ì²« í™”ë©´ ì´ë¯¸ì§€ ìƒì„± (appearance + background)
            initial_image = None
            if config.IMAGE_MODE_ENABLED:
                try:
                    # ComfyClient ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
                    if self.comfy_client is None:
                        self.comfy_client = ComfyClient()
                        logger.info("ComfyClient initialized")
                    
                    # appearanceì™€ backgroundë¥¼ ì¡°í•©í•´ì„œ ì´ë¯¸ì§€ ìƒì„±
                    appearance = config_data["character"].get("appearance", "")
                    char_age = config_data["character"].get("age", 21)
                    background = config_data.get("initial_background", "college library table, evening light")
                    
                    # appearanceì— ë‚˜ì´ ì¶”ê°€ (ì´ë¯¸ì§€ ìƒì„±ìš©)
                    if appearance and f"{char_age} years old" not in appearance.lower():
                        appearance = f"{char_age} years old, {appearance}".strip()
                    elif not appearance:
                        appearance = f"{char_age} years old"
                    
                    # visual_prompt ìƒì„±: backgroundë¥¼ í¬í•¨í•œ ì‹œê°ì  ë¬˜ì‚¬
                    visual_prompt = f"background: {background}, expression: neutral, looking at viewer"
                    
                    logger.info(f"Generating initial image with appearance: {appearance[:50]}... and background: {background}")
                    image_bytes = self.comfy_client.generate_image(
                        visual_prompt=visual_prompt,
                        appearance=appearance,
                        seed=-1
                    )
                    
                    if image_bytes:
                        # PIL Imageë¡œ ë³€í™˜
                        initial_image = Image.open(io.BytesIO(image_bytes))
                        # í˜„ì¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
                        self.current_image = initial_image
                        logger.info("Initial image generated successfully")
                    else:
                        logger.warning("Failed to generate initial image")
                except Exception as e:
                    logger.error(f"Failed to generate initial image: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
            
            status_msg = "âœ… ì„¤ì • ì €ì¥ ë° ì²« ëŒ€í™” ìƒì„± ì™„ë£Œ!"
            # íƒ­ ì „í™˜: chat_tabì˜ idë¥¼ ì‚¬ìš©
            return (status_msg, gr.Tabs(selected="chat_tab"), history, output_text, stats_text, initial_image, choices_text, thought_text, action_text)
        except Exception as e:
            logger.error(f"Failed to generate first dialogue: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return (f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ ì²« ëŒ€í™” ìƒì„± ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected="chat_tab"), [], "", "", None, "", "", "")
    
    def load_model(self) -> Tuple[str, bool]:
        """ëª¨ë¸ ë¡œë“œ (ì„¤ì •ì—ì„œ LLM provider ì •ë³´ ì½ì–´ì„œ ì´ˆê¸°í™”)"""
        if self.model_loaded and self.brain is not None:
            return "ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.", True
        
        try:
            # ì„¤ì •ì—ì„œ LLM ì„¤ì • ì½ê¸°
            config_data = self.load_config()
            llm_settings = config_data.get("llm_settings", {})
            provider = llm_settings.get("provider", "ollama")
            ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
            openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
            # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
            openrouter_api_key = self._load_openrouter_api_key()
            
            # Brain ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼ MemoryManagerë„ ì´ˆê¸°í™”)
            if self.brain is None:
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain = Brain(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            else:
                # Brainì´ ì´ë¯¸ ìˆìœ¼ë©´ memory_managerë§Œ ì¬ì´ˆê¸°í™”
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain.memory_manager = MemoryManager(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            
            logger.info(f"Brain initialized with {provider.upper()}, loading model...")
            
            # ëª¨ë¸ ë¡œë“œ ì‹œë„ (OpenRouter ì‹¤íŒ¨ ì‹œ Ollamaë¡œ í´ë°±)
            result = self.brain.memory_manager.load_model()
            if result is None and provider == "openrouter":
                logger.warning("OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„...")
                # Ollamaë¡œ í´ë°±
                self.brain.memory_manager = MemoryManager(
                    dev_mode=self.dev_mode,
                    provider="ollama",
                    model_name=ollama_model
                )
                result = self.brain.memory_manager.load_model()
                if result is None:
                    return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„í–ˆìœ¼ë‚˜ Ollamaë„ ì—°ê²° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", False
                self.model_loaded = True
                logger.info("Model loaded successfully (Ollama fallback)")
                return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°±í•˜ì—¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!", True
            
            if result is None:
                raise RuntimeError("ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            self.model_loaded = True
            logger.info("Model loaded successfully")
            return f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({provider.upper()})", True
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", False
    
    def process_turn(self, user_input: str, history: list) -> Tuple[list, str, str, str, str, str, str]:
        """í„´ ì²˜ë¦¬"""
        if not user_input.strip():
            return history, "", "", None, "", "", ""
        
        if self.brain is None:
            return history, "**ì˜¤ë¥˜**: Brainì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "", None, "", "", ""
        
        try:
            response = self.brain.generate_response(user_input)
        except Exception as e:
            logger.error(f"Turn processing failed: {e}")
            return history, f"**ì˜¤ë¥˜ ë°œìƒ**: {str(e)}", "", None, "", "", ""
        
        # ì‘ë‹µ íŒŒì‹±
        speech = response.get("speech", "")
        thought = response.get("thought", "")
        action_speech = response.get("action_speech", "")
        emotion = response.get("emotion", "neutral")
        stats = response.get("stats", {})
        mood = response.get("mood", "Neutral")
        relationship = response.get("relationship_status", "Stranger")
        gacha_tier = response.get("gacha_tier", "normal")  # ë‚´ë¶€ ì‹œìŠ¤í…œ ìš©ì–´
        multiplier = response.get("multiplier", 1.0)
        final_delta = response.get("final_delta", {})
        new_badge = response.get("new_badge")
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history = history or []
        history = list(history)
        history.append({"role": "user", "content": user_input})
        history.append({"role": "assistant", "content": speech})
        
        # ì¶œë ¥ í…ìŠ¤íŠ¸
        output_lines = [
            f"**{speech}**",
            "",
            f"*ì†ë§ˆìŒ: {thought}*",
            "",
            f"ê°ì •: {emotion} | ê¸°ë¶„: {mood} | ê´€ê³„: {relationship}"
        ]
        
        if gacha_tier != "normal":
            tier_emoji = {"jackpot": "ğŸ°", "surprise": "âœ¨", "critical": "ğŸ’¥"}.get(gacha_tier, "ğŸ²")
            # ì‚¬ìš©ìì—ê²ŒëŠ” "ë°˜ì‘ ì •ë„"ë¡œ í‘œì‹œ
            reaction_level = {"jackpot": "ê·¹ì§„í•œ ë°˜ì‘", "surprise": "ë†€ë¼ìš´ ë°˜ì‘", "critical": "ê°•ë ¬í•œ ë°˜ì‘"}.get(gacha_tier, "íŠ¹ë³„í•œ ë°˜ì‘")
            output_lines.append(f"{tier_emoji} **{reaction_level}** (ë°°ìœ¨: x{multiplier:.1f})")
        
        if new_badge:
            output_lines.append(f"ğŸ† **ë±ƒì§€ íšë“: {new_badge}**")
        
        delta_parts = []
        for key, value in final_delta.items():
            if value != 0:
                sign = "+" if value > 0 else ""
                color = "green" if value > 0 else "red"
                delta_parts.append(f"<span style='color: {color}'>{key}: {sign}{value:.1f}</span>")
        
        if delta_parts:
            output_lines.append(f"ë³€í™”: {' | '.join(delta_parts)}")
        
        output_text = "\n".join(output_lines)
        
        def format_delta(key: str) -> str:
            delta_value = final_delta.get(key, 0)
            if delta_value > 0:
                return f'<span style="color: blue;">(+{delta_value:.0f})</span>'
            elif delta_value < 0:
                return f'<span style="color: red;">({delta_value:.0f})</span>'
            else:
                return '<span style="color: black;">(0)</span>'
        
        # ë°˜ì‘ ì •ë„ í‘œì‹œ (ì „êµ¬ ì•„ì´ì½˜)
        def format_reaction_indicators(tier: str) -> str:
            """ë°˜ì‘ ì •ë„ì— ë”°ë¼ ì „êµ¬/ë²ˆê°œ/í­ë°œ ì•„ì´ì½˜ í‘œì‹œ"""
            if tier == "jackpot":
                # í­ë°œ ì´ëª¨í‹°ì½˜ 4ê°œ
                return "ğŸ’¥ ğŸ’¥ ğŸ’¥ ğŸ’¥"
            elif tier == "surprise":
                # ë²ˆê°œ 3ê°œ, êº¼ì§„ ì „êµ¬ 1ê°œ
                return "âš¡ âš¡ âš¡ âš«"
            elif tier == "critical":
                # ë…¸ë€ ì „êµ¬ 2ê°œ, êº¼ì§„ ì „êµ¬ 2ê°œ
                return "ğŸ’¡ ğŸ’¡ âš« âš«"
            else:  # normal
                # ë…¸ë€ ì „êµ¬ 1ê°œ, êº¼ì§„ ì „êµ¬ 3ê°œ
                return "ğŸ’¡ âš« âš« âš«"
        
        reaction_indicators = format_reaction_indicators(gacha_tier)
        
        stats_text = f"""
**ë°˜ì‘ ì •ë„:** {reaction_indicators} (x{multiplier:.1f})

**6ì¶• ìˆ˜ì¹˜:**
- P (ì¾Œë½): {stats.get('P', 0):.0f} {format_delta('P')}
- A (ê°ì„±): {stats.get('A', 0):.0f} {format_delta('A')}
- D (ì§€ë°°): {stats.get('D', 0):.0f} {format_delta('D')}
- I (ì¹œë°€): {stats.get('I', 0):.0f} {format_delta('I')}
- T (ì‹ ë¢°): {stats.get('T', 0):.0f} {format_delta('T')}
- Dep (ì˜ì¡´): {stats.get('Dep', 0):.0f} {format_delta('Dep')}

**ìƒíƒœ:**
- ê´€ê³„: {relationship}
- ê¸°ë¶„: {mood}
- ë±ƒì§€: {', '.join(response.get('badges', [])) or 'None'}
"""
        
        # ì´ë¯¸ì§€ ìƒì„± (visual_change_detectedê°€ trueì´ê±°ë‚˜ 5í„´ ì´ìƒ ì§€ë‚¬ì„ ë•Œ)
        image = None
        visual_change_detected = response.get("visual_change_detected", False)
        image_generation_reasons = response.get("image_generation_reasons", [])
        new_image_generated = False  # ìƒˆ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì¶”ì 
        
        if visual_change_detected and config.IMAGE_MODE_ENABLED:
            # LLM ëª¨ë¸ offloadë¥¼ ìœ„í•œ 2ì´ˆ ëŒ€ê¸°
            import time
            logger.info("Waiting 2 second for LLM model offload...")
            time.sleep(2.0)
            
            # ì´ë¯¸ì§€ ìƒì„± ì´ìœ  ë¡œê·¸ ì¶œë ¥
            if image_generation_reasons:
                logger.info("=" * 80)
                logger.info("ğŸ¨ [ComfyUI ì´ë¯¸ì§€ ìƒì„± ì‹œì‘]")
                logger.info("=" * 80)
                logger.info("ì´ë¯¸ì§€ ìƒì„± ì´ìœ :")
                for i, reason in enumerate(image_generation_reasons, 1):
                    logger.info(f"  {i}. {reason}")
                logger.info("=" * 80)
            else:
                logger.info("ğŸ¨ [ComfyUI ì´ë¯¸ì§€ ìƒì„± ì‹œì‘] (ì´ìœ : visual_change_detected=true)")
            
            try:
                # ComfyClient ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
                if self.comfy_client is None:
                    self.comfy_client = ComfyClient()
                    logger.info("ComfyClient initialized")
                
                # ì„¤ì •ì—ì„œ appearanceì™€ ë‚˜ì´ ê°€ì ¸ì˜¤ê¸°
                saved_config = self.load_config()
                appearance = saved_config["character"].get("appearance", "")
                char_age = saved_config["character"].get("age", 21)
                
                # appearanceì— ë‚˜ì´ ì¶”ê°€ (ì´ë¯¸ì§€ ìƒì„±ìš©)
                if appearance and f"{char_age} years old" not in appearance.lower():
                    appearance = f"{char_age} years old, {appearance}".strip()
                elif not appearance:
                    appearance = f"{char_age} years old"
                
                # responseì—ì„œ visual_promptì™€ background ê°€ì ¸ì˜¤ê¸°
                visual_prompt = response.get("visual_prompt", "")
                background = response.get("background", "")
                
                # visual_promptê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                if not visual_prompt:
                    visual_prompt = f"background: {background}, expression: {emotion}, looking at viewer"
                elif background and "background:" not in visual_prompt.lower():
                    # visual_promptì— backgroundê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                    visual_prompt = f"{visual_prompt}, background: {background}"
                
                logger.info(f"  appearance: {appearance[:50]}...")
                logger.info(f"  visual_prompt: {visual_prompt[:100]}...")
                
                image_bytes = self.comfy_client.generate_image(
                    visual_prompt=visual_prompt,
                    appearance=appearance,
                    seed=-1
                )
                
                if image_bytes:
                    # PIL Imageë¡œ ë³€í™˜
                    image = Image.open(io.BytesIO(image_bytes))
                    # í˜„ì¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
                    self.current_image = image
                    new_image_generated = True  # ìƒˆ ì´ë¯¸ì§€ ìƒì„±ë¨
                    logger.info("Image generated successfully")
                else:
                    logger.warning("Failed to generate image (returned None)")
            except Exception as e:
                logger.error(f"Failed to generate image: {e}")
                import traceback
                logger.error(traceback.format_exc())
                # ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨í•´ë„ ëŒ€í™”ëŠ” ê³„ì† ì§„í–‰
        
        # ìƒˆ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì´ì „ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë¡œë”© ì°½ ë°©ì§€)
        if not new_image_generated:
            image = self.current_image
        
        choices_text = "ë‹¤ìŒ ëŒ€ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        thought_text = f"ğŸ’­ **ì†ë§ˆìŒ**: {thought}" if thought else ""
        action_text = f"ğŸ­ **í–‰ë™**: {action_speech}" if action_speech else ""
        
        return history, output_text, stats_text, image, choices_text, thought_text, action_text
    
    def create_ui(self):
        """Gradio UI ìƒì„±"""
        # ì„¤ì • ë¡œë“œ
        saved_config = self.load_config()
        
        with gr.Blocks(title="Zeniji Emotion Simul") as demo:
            gr.Markdown("# ğŸ® Zeniji Emotion Simul")
            
            with gr.Tabs() as tabs:
                # ========== íƒ­ 1: ì´ˆê¸° ì„¤ì • ==========
                with gr.Tab("âš™ï¸ ì´ˆê¸° ì„¤ì •", id="setup_tab") as setup_tab:
                    gr.Markdown("## ìºë¦­í„° ë° ì‹œë‚˜ë¦¬ì˜¤ ì´ˆê¸° ì„¤ì •")
                    
                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ‘¤ ì£¼ì¸ê³µ ì„¤ì •")
                            player_name = gr.Textbox(
                                label="ì´ë¦„",
                                value=saved_config["player"].get("name", ""),
                                placeholder="í”Œë ˆì´ì–´ ì´ë¦„"
                            )
                            player_gender = gr.Radio(
                                label="ì„±ë³„",
                                choices=["ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€"],
                                value=saved_config["player"].get("gender", "ë‚¨ì„±")
                            )
                        
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ‘¥ ìƒëŒ€ë°© ì„¤ì •")
                            char_name = gr.Textbox(
                                label="ì´ë¦„",
                                value=saved_config["character"].get("name", "ì˜ˆë‚˜"),
                                placeholder="ìºë¦­í„° ì´ë¦„"
                            )
                            # character ì •ë³´ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
                            character_info = saved_config.get("character") or {}
                            char_age_val = character_info.get("age")
                            char_age_val = int(char_age_val) if char_age_val is not None else 21
                            
                            char_age = gr.Slider(
                                label="ë‚˜ì´",
                                minimum=18,
                                maximum=100,
                                value=char_age_val,
                                step=1
                            )
                            char_gender = gr.Radio(
                                label="ì„±ë³„",
                                choices=["ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€"],
                                value=saved_config["character"].get("gender", "ì—¬ì„±")
                            )
                    
                    gr.Markdown("### ğŸ“ ì™¸ëª¨ ë° ì„±ê²©")
                    appearance = gr.Textbox(
                        label="ì™¸ëª¨ ë¬˜ì‚¬ (ì˜ì–´ íƒœê·¸ í˜•ì‹)",
                        value=saved_config["character"].get("appearance", ""),
                        placeholder="ì˜ˆ: korean beauty, short hair, brown eyes, cute face, casual outfit",
                        info="ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ íƒœê·¸ë¡œ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                        lines=3,
                        max_lines=5
                    )
                    personality = gr.Textbox(
                        label="ì„±ê²© ë¬˜ì‚¬",
                        value=saved_config["character"].get("personality", ""),
                        placeholder="ì˜ˆ: ë°ê³  í™œë°œí•˜ì§€ë§Œ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ ì•ì—ì„œëŠ” ìˆ˜ì¤ìŒì´ ë§ìŒ",
                        lines=3,
                        max_lines=5
                    )
                    
                    gr.Markdown("### ğŸ“Š ì‹¬ë¦¬ ì§€í‘œ ì„¤ì • (6ì¶• ì‹œìŠ¤í…œ)")
                    gr.Markdown("ê° ìˆ˜ì¹˜ëŠ” 0~100 ì‚¬ì´ì´ë©°, ì´ˆê¸°ê°’ì€ **ìµœëŒ€ 70**ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤.")
                    
                    # initial_statsê°€ ì—†ê±°ë‚˜ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    initial_stats = saved_config.get("initial_stats") or {}
                    
                    def safe_get_stat(key: str, default: float) -> float:
                        """ì•ˆì „í•˜ê²Œ í†µê³„ ê°’ ê°€ì ¸ì˜¤ê¸° (None ì²´í¬) - ëª…ì‹œì ìœ¼ë¡œ í•œ ë²ˆ ë” or ì²˜ë¦¬"""
                        val = initial_stats.get(key)
                        if val is None:
                            return default
                        try:
                            result = float(val)
                            # NaNì´ë‚˜ inf ì²´í¬
                            if not (0 <= result <= 100):
                                return default
                            return result
                        except (ValueError, TypeError):
                            return default
                    
                    with gr.Row():
                        with gr.Column():
                            # ëª…ì‹œì ìœ¼ë¡œ or ì²˜ë¦¬ë¡œ None ë°©ì§€
                            p_val = gr.Slider(
                                label="P (Pleasure) - ì¾Œë½",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("P", 50.0) or 50.0,
                                step=1.0,
                                info="ê´€ê³„ì˜ ê¸ì •/ë¶€ì •"
                            )
                            a_val = gr.Slider(
                                label="A (Arousal) - ê°ì„±",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("A", 40.0) or 40.0,
                                step=1.0,
                                info="ê¸´ì¥ê°/ì—ë„ˆì§€"
                            )
                            d_val = gr.Slider(
                                label="D (Dominance) - ì§€ë°°",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("D", 40.0) or 40.0,
                                step=1.0,
                                info="ê´€ê³„ì˜ ì£¼ë„ê¶Œ"
                            )
                        with gr.Column():
                            i_val = gr.Slider(
                                label="I (Intimacy) - ì¹œë°€",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("I", 20.0) or 20.0,
                                step=1.0,
                                info="ì •ì„œì  ì¹œë°€ê°"
                            )
                            t_val = gr.Slider(
                                label="T (Trust) - ì‹ ë¢°",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("T", 50.0) or 50.0,
                                step=1.0,
                                info="ì‹ ë¢°ë„"
                            )
                            dep_val = gr.Slider(
                                label="Dep (Dependency) - ì˜ì¡´",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("Dep", 0.0) or 0.0,
                                step=1.0,
                                info="ì˜ì¡´/ì§‘ì°©ë„"
                            )
                    
                    gr.Markdown("### ğŸ­ í”„ë¦¬ì…‹")
                    with gr.Row():
                        for preset_name in PRESETS.keys():
                            preset_btn = gr.Button(preset_name, variant="secondary")
                            # lambda í´ë¡œì € ë¬¸ì œ í•´ê²° ë° fn ëª…ì‹œ
                            def make_preset_handler(name):
                                def handler():
                                    return self.apply_preset(name)
                                return handler
                            preset_btn.click(
                                fn=make_preset_handler(preset_name),
                                inputs=[],
                                outputs=[p_val, a_val, d_val, i_val, t_val, dep_val, appearance, personality]
                            )
                    
                    gr.Markdown("### ğŸ“– ì´ˆê¸° ìƒí™©")
                    initial_context = gr.Textbox(
                        label="ì´ˆê¸° ìƒí™© ì„¤ëª…",
                        value=saved_config.get("initial_context", ""),
                        placeholder="ëŒ€í™”ê°€ ì‹œì‘ë˜ëŠ” ë°°ê²½ ìƒí™©ì„ ì„¤ëª…í•˜ì„¸ìš”.",
                        lines=4,
                        max_lines=6
                    )
                    initial_background = gr.Textbox(
                        label="ë°°ê²½ (ì˜ì–´)",
                        value=saved_config.get("initial_background", "college library table, evening light"),
                        placeholder="college library table, evening light",
                        info="ì´ë¯¸ì§€ ìƒì„±ìš© ë°°ê²½ ì„¤ëª… (ì˜ì–´)"
                    )
                    
                    # TODO: ëœë¤ ìƒí™© ìƒì„± ë²„íŠ¼
                    # random_context_btn = gr.Button("ğŸ² ëœë¤ ìƒí™© ìƒì„±", variant="secondary")
                    
                    setup_status = gr.Markdown("")
                    start_btn = gr.Button("ğŸ’¾ ì €ì¥ ë° ë°”ë¡œ ì‹œì‘", variant="primary", size="lg")
                
                # ========== íƒ­ 2: ëŒ€í™” ==========
                with gr.Tab("ğŸ’¬ ëŒ€í™”", id="chat_tab") as chat_tab:
                    with gr.Row():
                        with gr.Column(scale=2):
                            chatbot = gr.Chatbot(label="ëŒ€í™”", height=400)
                            
                            # ì†ë§ˆìŒ: Accordionìœ¼ë¡œ ì ‘ê¸°/í¼ì¹˜ê¸° ê°€ëŠ¥í•˜ê²Œ
                            with gr.Accordion("ğŸ’­ ì†ë§ˆìŒ ë³´ê¸°", open=False, visible=True) as thought_accordion:
                                thought_display = gr.Markdown(label="", visible=True)
                            
                            action_display = gr.Markdown(label="ğŸ­ í–‰ë™", visible=True)
                            user_input = gr.Textbox(label="ì…ë ¥", placeholder="ë§ì„ ì…ë ¥í•˜ì„¸ìš”...", interactive=False)
                            submit_btn = gr.Button("ì „ì†¡", variant="primary", interactive=False)
                        
                        with gr.Column(scale=1):
                            stats_display = gr.Markdown(label="ìƒíƒœ")
                            image_display = gr.Image(label="ìºë¦­í„°", height=400)
                    
                    # ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°ìš© hidden state
                    image_update_trigger = gr.State(value=None)
                    
                    def on_submit(message, history):
                        if not self.model_loaded:
                            return history, "", "", "", "", None  # ë§ˆì§€ë§‰ì€ trigger
                        new_history, output, stats, image, choices, thought, action = self.process_turn(message, history)
                        
                        # imageê°€ ìƒˆë¡œ ìƒì„±ëìœ¼ë©´ triggerì— ë„£ê³ , ì•„ë‹ˆë©´ None
                        return new_history, "", stats, thought, action, image
                    
                    def update_image_if_needed(trigger_image):
                        """íŠ¸ë¦¬ê±°ì— ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ ë°˜í™˜, ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ ì•ˆ í•¨"""
                        if trigger_image is not None:
                            return trigger_image
                        return gr.skip()  # Gradio 6.x: ì—…ë°ì´íŠ¸ ê±´ë„ˆë›°ê¸°
                    
                    # ë©”ì¸ submit - ì´ë¯¸ì§€ ì œì™¸
                    submit_btn.click(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display]
                    )
                    
                    user_input.submit(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display]
                    )
                    
                    # ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ì‹œ UI í™œì„±í™”
                    def enable_chat_ui():
                        if self.model_loaded:
                            return (
                                gr.Button(interactive=True),  # submit_btn
                                gr.Textbox(interactive=True)  # user_input
                            )
                        return (
                            gr.Button(interactive=False),
                            gr.Textbox(interactive=False)
                        )
                    
                    # íƒ­ ì „í™˜ ì‹œ UI ìƒíƒœ í™•ì¸
                    chat_tab.select(
                        enable_chat_ui,
                        inputs=[],
                        outputs=[submit_btn, user_input]
                    )
                
                # ========== íƒ­ 3: í™˜ê²½ì„¤ì • ==========
                with gr.Tab("âš™ï¸ í™˜ê²½ì„¤ì •", id="settings_tab"):
                    gr.Markdown("## LLM ì„¤ì •")
                    
                    # LLM ì„¤ì • ë¡œë“œ
                    llm_settings = saved_config.get("llm_settings", {})
                    provider = llm_settings.get("provider", "ollama")
                    ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
                    openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
                    # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                    openrouter_api_key = self._load_openrouter_api_key()
                    
                    llm_provider = gr.Radio(
                        label="LLM Provider",
                        choices=["ollama", "openrouter"],
                        value=provider,
                        info="ì‚¬ìš©í•  LLM ì„œë¹„ìŠ¤ ì„ íƒ"
                    )
                    
                    with gr.Group(visible=(provider == "ollama")) as ollama_group:
                        ollama_model_input = gr.Textbox(
                            label="Ollama ëª¨ë¸ ì´ë¦„",
                            value=ollama_model,
                            placeholder="ì˜ˆ: kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                            info="'ollama list' ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•œ ì •í™•í•œ ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
                        )
                    
                    with gr.Group(visible=(provider == "openrouter")) as openrouter_group:
                        openrouter_api_key_input = gr.Textbox(
                            label="OpenRouter API í‚¤",
                            value=openrouter_api_key,
                            placeholder="sk-or-v1-...",
                            type="password",
                            info="OpenRouter API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (https://openrouter.ai/keys)"
                        )
                        openrouter_model_input = gr.Textbox(
                            label="OpenRouter ëª¨ë¸",
                            value=openrouter_model,
                            placeholder="ì˜ˆ: cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
                            info="OpenRouterì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„"
                        )
                    
                    # Provider ë³€ê²½ ì‹œ UI í‘œì‹œ/ìˆ¨ê¹€
                    def update_provider_ui(selected_provider):
                        return (
                            gr.Group(visible=(selected_provider == "ollama")),
                            gr.Group(visible=(selected_provider == "openrouter"))
                        )
                    
                    llm_provider.change(
                        update_provider_ui,
                        inputs=[llm_provider],
                        outputs=[ollama_group, openrouter_group]
                    )
                    
                    settings_status = gr.Markdown("")
                    save_settings_btn = gr.Button("ğŸ’¾ ì„¤ì • ì €ì¥", variant="primary")
                    
                    def save_llm_settings(provider_val, ollama_model_val, openrouter_key_val, openrouter_model_val):
                        """LLM ì„¤ì • ì €ì¥"""
                        try:
                            config_data = self.load_config()
                            
                            # OpenRouter API í‚¤ëŠ” ë³„ë„ íŒŒì¼ì— ì €ì¥
                            if provider_val == "openrouter" and openrouter_key_val:
                                if not self._save_openrouter_api_key(openrouter_key_val):
                                    return "âŒ OpenRouter API í‚¤ ì €ì¥ ì‹¤íŒ¨"
                            
                            # LLM ì„¤ì • ì—…ë°ì´íŠ¸ (API í‚¤ëŠ” ì œì™¸)
                            config_data["llm_settings"] = {
                                "provider": provider_val,
                                "ollama_model": ollama_model_val or "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                                "openrouter_model": openrouter_model_val or "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
                            }
                            
                            # ì„¤ì • ì €ì¥
                            if self.save_config(config_data):
                                # Brain ì¬ì´ˆê¸°í™” (ìƒˆ ì„¤ì • ì ìš©)
                                try:
                                    if self.brain is not None:
                                        # ê¸°ì¡´ Brainì˜ memory_managerë¥¼ ìƒˆ ì„¤ì •ìœ¼ë¡œ ì¬ì´ˆê¸°í™”
                                        llm_settings = config_data["llm_settings"]
                                        # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                                        api_key = self._load_openrouter_api_key() if llm_settings["provider"] == "openrouter" else None
                                        self.brain.memory_manager = MemoryManager(
                                            dev_mode=self.dev_mode,
                                            provider=llm_settings["provider"],
                                            model_name=llm_settings["ollama_model"] if llm_settings["provider"] == "ollama" else llm_settings["openrouter_model"],
                                            api_key=api_key
                                        )
                                        
                                        # ëª¨ë¸ ë¡œë“œ ì‹œë„ (OpenRouter ì‹¤íŒ¨ ì‹œ Ollamaë¡œ í´ë°±)
                                        result = self.brain.memory_manager.load_model()
                                        if result is None and llm_settings["provider"] == "openrouter":
                                            logger.warning("OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„...")
                                            # Ollamaë¡œ í´ë°±
                                            config_data["llm_settings"]["provider"] = "ollama"
                                            self.brain.memory_manager = MemoryManager(
                                                dev_mode=self.dev_mode,
                                                provider="ollama",
                                                model_name=llm_settings["ollama_model"]
                                            )
                                            result = self.brain.memory_manager.load_model()
                                            if result is None:
                                                return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„í–ˆìœ¼ë‚˜ Ollamaë„ ì—°ê²° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                                            return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°±í•˜ì—¬ ì„¤ì • ì €ì¥ ì™„ë£Œ."
                                        
                                        self.model_loaded = (result is not None)
                                        if self.model_loaded:
                                            return f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ! ({llm_settings['provider'].upper()} ì—°ê²° ì„±ê³µ)"
                                        else:
                                            return f"âš ï¸ ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ {llm_settings['provider'].upper()} ì—°ê²° ì‹¤íŒ¨"
                                    else:
                                        return "âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ! (ë‹¤ìŒ ì‹œì‘ ì‹œ ì ìš©ë©ë‹ˆë‹¤)"
                                except Exception as e:
                                    logger.error(f"Failed to reinitialize Brain: {e}")
                                    return f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ ëª¨ë¸ ì¬ì—°ê²° ì‹¤íŒ¨: {str(e)}"
                            else:
                                return "âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨"
                        except Exception as e:
                            logger.error(f"Failed to save LLM settings: {e}")
                            return f"âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}"
                    
                    save_settings_btn.click(
                        save_llm_settings,
                        inputs=[llm_provider, ollama_model_input, openrouter_api_key_input, openrouter_model_input],
                        outputs=[settings_status]
                    )
            
            # ì²« íƒ­ì˜ ë²„íŠ¼ í´ë¦­ ì‹œ ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸ (íƒ­ ë°–ì—ì„œ ì •ì˜)
            start_btn.click(
                self.validate_and_start,
                inputs=[
                    player_name, player_gender,
                    char_name, char_age, char_gender,
                    appearance, personality,
                    p_val, a_val, d_val, i_val, t_val, dep_val,
                    initial_context, initial_background
                ],
                outputs=[
                    setup_status, tabs,
                    chatbot, gr.Textbox(visible=False), stats_display, image_display,
                    gr.Textbox(visible=False), thought_display, action_display
                ]
            )
            
            # ì„¤ì • ë¡œë“œ ì‹œ UI ì—…ë°ì´íŠ¸
            demo.load(
                enable_chat_ui,
                inputs=[],
                outputs=[submit_btn, user_input]
            )
        
        return demo


def parse_args():
    parser = argparse.ArgumentParser(description="Zeniji Emotion Simul")
    parser.add_argument("--dev-mode", action="store_true", help="ê°œë°œì ëª¨ë“œ í™œì„±í™”")
    parser.add_argument("--log-level", default="INFO", help="ë¡œê¹… ë ˆë²¨ ì„¤ì •")
    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    args = parse_args()
    logging.getLogger().setLevel(getattr(logging, args.log_level.upper(), logging.INFO))

    app = GameApp(dev_mode=args.dev_mode)
    demo = app.create_ui()
    print("\n" + "=" * 60)
    print("ğŸš€ Gradio ì„œë²„ ì‹œì‘ ì¤‘...")
    print("=" * 60)
    print(f"ğŸ“ ë¡œì»¬ ì ‘ì†: http://localhost:7860")
    print(f"ğŸ“ ë„¤íŠ¸ì›Œí¬ ì ‘ì†: http://127.0.0.1:7860")
    if args.dev_mode:
        print("ğŸ›   Dev Mode ON")
    print("=" * 60 + "\n")
    demo.launch(server_name="127.0.0.1", server_port=7860, share=False)


if __name__ == "__main__":
    main()
