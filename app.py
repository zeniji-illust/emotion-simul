"""
Zeniji Emotion Simul - Main Application
Gradio UI ë° ê²Œì„ ë£¨í”„
"""

import gradio as gr
import logging
import argparse
import json
import os
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
from brain import Brain
from state_manager import CharacterState
from comfy_client import ComfyClient
from memory_manager import MemoryManager
from PIL import Image
import io
import config
import plotly.graph_objects as go
from cryptography.fernet import Fernet
import base64

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("App")

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_FILE = Path("character_config.json")  # ê¸°ë³¸ ì„¤ì • íŒŒì¼ (í•˜ìœ„ í˜¸í™˜ì„±)
CHARACTER_DIR = Path("characters")
ENV_CONFIG_DIR = Path("env_config")
ENV_CONFIG_FILE = ENV_CONFIG_DIR / "settings.json"
API_KEY_DIR = Path("apikey")
OPENROUTER_API_KEY_FILE = API_KEY_DIR / "openrouter_api_key.txt"
SCENARIOS_DIR = Path("scenarios")

# í”„ë¦¬ì…‹ ì •ì˜
PRESETS = {
    "ì†Œê¿‰ì¹œêµ¬": {
        "P": 60.0, "A": 50.0, "D": 45.0, "I": 70.0, "T": 70.0, "Dep": 30.0,
        "appearance": "korean beauty, friendly face, warm expression, casual clothes, childhood friend",
        "personality": "ë°ê³  í™œë°œí•˜ë©°, ì˜¤ëœ ì¹œêµ¬ë¼ì„œ í¸í•˜ê²Œ ëŒ€í™”í•¨. ë•Œë¡œëŠ” ì¥ë‚œìŠ¤ëŸ½ì§€ë§Œ ì§„ì‹¬ì´ ë‹´ê²¨ìˆìŒ."
    },
    "í˜ê´€ ë¼ì´ë²Œ": {
        "P": 20.0, "A": 70.0, "D": 80.0, "I": 10.0, "T": 10.0, "Dep": 0.0,
        "appearance": "korean beauty, sharp eyes, confident expression, competitive look, strong presence",
        "personality": "í•­ìƒ ê²½ìŸí•˜ê³  ì‹¶ì–´í•˜ë©°, ë‹¹ì‹ ì„ ë¼ì´ë²Œë¡œ ì¸ì‹. ë„ì „ì ì´ê³  ìì¡´ì‹¬ì´ ê°•í•¨."
    },
    "í”¼í/ì§‘ì°©": {
        "P": 30.0, "A": 80.0, "D": 20.0, "I": 90.0, "T": 20.0, "Dep": 90.0,
        "appearance": "korean beauty, tired eyes, intense gaze, unstable expression, obsessive look",
        "personality": "ë‹¹ì‹ ì—ê²Œ ê°•í•˜ê²Œ ì§‘ì°©í•˜ë©°, ë–¨ì–´ì§€ë©´ ë¶ˆì•ˆí•´í•¨. ê°ì • ê¸°ë³µì´ ì‹¬í•˜ê³  ì˜ì¡´ì ."
    }
}


class GameApp:
    """ê²Œì„ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, dev_mode: bool = False):
        self.dev_mode = dev_mode
        self.brain = None
        self.model_loaded = False
        self.current_image: Optional[Image.Image] = None  # PIL Image ì €ì¥
        self.current_chart: Optional[go.Figure] = None  # ì´ì „ ì°¨íŠ¸ ì €ì¥ (ë¡œë”© ì¤‘ ìœ ì§€ìš©)
        self.comfy_client = None
    
    def load_config(self) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ - None ê°’ ì •ë¦¬"""
        if CONFIG_FILE.exists():
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # None ê°’ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                    return self._sanitize_config(config)
            except Exception as e:
                logger.warning(f"Failed to load config: {e}")
        return self._default_config()
    
    def _sanitize_config(self, config: Dict) -> Dict:
        """ì„¤ì •ì—ì„œ None ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´"""
        default = self._default_config()
        
        # initial_statsì˜ None ê°’ ì²˜ë¦¬
        initial_stats = config.get("initial_stats", {}) or {}
        sanitized_stats = {}
        for key in ["P", "A", "D", "I", "T", "Dep"]:
            val = initial_stats.get(key)
            if val is None:
                val = default["initial_stats"][key]
            sanitized_stats[key] = float(val) if val is not None else default["initial_stats"][key]
        
        # characterì˜ age ì²˜ë¦¬
        character = config.get("character", {}) or {}
        char_age = character.get("age")
        if char_age is None:
            char_age = default["character"]["age"]
        
        # None ê°’ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³‘í•©
        result = default.copy()
        result.update(config)
        result["initial_stats"] = sanitized_stats
        if "character" in result:
            result["character"]["age"] = int(char_age) if char_age is not None else default["character"]["age"]
        
        return result
    
    def _get_encryption_key(self) -> bytes:
        """ì•”í˜¸í™” í‚¤ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        key_file = Path.home() / ".zeniji_encryption_key"
        
        if key_file.exists():
            # ê¸°ì¡´ í‚¤ ë¡œë“œ
            try:
                with open(key_file, 'rb') as f:
                    return f.read()
            except Exception as e:
                logger.warning(f"Failed to load encryption key: {e}, generating new key")
                # í‚¤ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ìƒì„±
                key = Fernet.generate_key()
                try:
                    key_file.parent.mkdir(exist_ok=True)
                    with open(key_file, 'wb') as f:
                        f.write(key)
                    # Windowsì—ì„œëŠ” chmodê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                    try:
                        os.chmod(key_file, 0o600)
                    except:
                        pass
                    return key
                except Exception as e2:
                    logger.error(f"Failed to save encryption key: {e2}")
                    raise
        else:
            # ìƒˆ í‚¤ ìƒì„±
            key = Fernet.generate_key()
            try:
                key_file.parent.mkdir(exist_ok=True)
                with open(key_file, 'wb') as f:
                    f.write(key)
                # Windowsì—ì„œëŠ” chmodê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                try:
                    os.chmod(key_file, 0o600)
                except:
                    pass
                logger.info(f"Encryption key generated at {key_file}")
                return key
            except Exception as e:
                logger.error(f"Failed to create encryption key: {e}")
                raise
    
    def _encrypt_api_key(self, api_key: str) -> str:
        """API í‚¤ ì•”í˜¸í™”"""
        try:
            key = self._get_encryption_key()
            fernet = Fernet(key)
            encrypted = fernet.encrypt(api_key.encode())
            return base64.b64encode(encrypted).decode()
        except Exception as e:
            logger.error(f"Failed to encrypt API key: {e}")
            raise
    
    def _decrypt_api_key(self, encrypted_key: str) -> str:
        """API í‚¤ ë³µí˜¸í™”"""
        try:
            key = self._get_encryption_key()
            fernet = Fernet(key)
            encrypted = base64.b64decode(encrypted_key.encode())
            return fernet.decrypt(encrypted).decode()
        except Exception as e:
            logger.error(f"Failed to decrypt API key: {e}")
            raise
    
    def _is_encrypted(self, content: str) -> bool:
        """íŒŒì¼ ë‚´ìš©ì´ ì•”í˜¸í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        # ì•”í˜¸í™”ëœ ë‚´ìš©ì€ base64ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆê³ , íŠ¹ì • íŒ¨í„´ì„ ê°€ì§
        try:
            # base64 ë””ì½”ë”© ì‹œë„
            decoded = base64.b64decode(content.encode())
            # Fernet ì•”í˜¸í™”ëœ ë°ì´í„°ëŠ” í•­ìƒ 32ë°”ì´íŠ¸ í‚¤ + íŠ¹ì • êµ¬ì¡°ë¥¼ ê°€ì§
            return len(decoded) > 0 and len(content) > 50
        except:
            return False
    
    def _migrate_plaintext_key(self) -> bool:
        """ê¸°ì¡´ í‰ë¬¸ API í‚¤ë¥¼ ì•”í˜¸í™”í•˜ì—¬ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        try:
            if not OPENROUTER_API_KEY_FILE.exists():
                return False
            
            # íŒŒì¼ ì½ê¸°
            with open(OPENROUTER_API_KEY_FILE, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            if not content:
                return False
            
            # ì´ë¯¸ ì•”í˜¸í™”ë˜ì–´ ìˆìœ¼ë©´ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš”
            if self._is_encrypted(content):
                return False
            
            # í‰ë¬¸ í‚¤ë¥¼ ì•”í˜¸í™”í•˜ì—¬ ì €ì¥
            encrypted = self._encrypt_api_key(content)
            with open(OPENROUTER_API_KEY_FILE, 'w', encoding='utf-8') as f:
                f.write(encrypted)
            
            logger.info("Migrated plaintext API key to encrypted format")
            return True
        except Exception as e:
            logger.warning(f"Failed to migrate plaintext API key: {e}")
            return False
    
    def _load_openrouter_api_key(self) -> str:
        """OpenRouter API í‚¤ë¥¼ íŒŒì¼ì—ì„œ ë³µí˜¸í™”í•˜ì—¬ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë„ (ê¸°ì¡´ í‰ë¬¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ì•”í˜¸í™”)
            self._migrate_plaintext_key()
            
            if OPENROUTER_API_KEY_FILE.exists():
                with open(OPENROUTER_API_KEY_FILE, 'r', encoding='utf-8') as f:
                    encrypted = f.read().strip()
                    if encrypted:
                        # ì•”í˜¸í™”ë˜ì–´ ìˆìœ¼ë©´ ë³µí˜¸í™”, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                        if self._is_encrypted(encrypted):
                            return self._decrypt_api_key(encrypted)
                        else:
                            # í‰ë¬¸ì´ë©´ ìë™ìœ¼ë¡œ ì•”í˜¸í™”í•˜ì—¬ ì €ì¥
                            logger.warning("Found plaintext API key, encrypting...")
                            self._save_openrouter_api_key(encrypted)
                            return encrypted
            return ""
        except Exception as e:
            logger.warning(f"Failed to load OpenRouter API key: {e}")
            return ""
    
    def _save_openrouter_api_key(self, api_key: str) -> bool:
        """OpenRouter API í‚¤ë¥¼ ì•”í˜¸í™”í•˜ì—¬ íŒŒì¼ì— ì €ì¥"""
        try:
            # apikey ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            API_KEY_DIR.mkdir(exist_ok=True)
            
            # API í‚¤ ì•”í˜¸í™”í•˜ì—¬ ì €ì¥
            encrypted = self._encrypt_api_key(api_key.strip())
            with open(OPENROUTER_API_KEY_FILE, 'w', encoding='utf-8') as f:
                f.write(encrypted)
            
            logger.info(f"OpenRouter API key saved (encrypted) to {OPENROUTER_API_KEY_FILE}")
            return True
        except Exception as e:
            logger.error(f"Failed to save OpenRouter API key: {e}")
            return False
    
    def load_env_config(self) -> Dict:
        """í™˜ê²½ì„¤ì • íŒŒì¼ ë¡œë“œ (LLM ë° ComfyUI ì„¤ì •)"""
        if ENV_CONFIG_FILE.exists():
            try:
                with open(ENV_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Failed to load env config: {e}")
        return self._default_env_config()
    
    def _default_env_config(self) -> Dict:
        """ê¸°ë³¸ í™˜ê²½ì„¤ì • ë°˜í™˜"""
        return {
            "llm_settings": {
                "provider": "ollama",
                "ollama_model": "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                "openrouter_model": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
            },
            "comfyui_settings": {
                "server_port": 8000,
                "workflow_path": "workflows/comfyui_zit.json",
                "model_name": "Zeniji_mix_ZiT_v1.safetensors",
                "steps": 9,
                "cfg": 1,
                "sampler_name": "euler",
                "scheduler": "simple"
            }
        }
    
    def save_env_config(self, env_config: Dict) -> bool:
        """í™˜ê²½ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            # env_config ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            ENV_CONFIG_DIR.mkdir(exist_ok=True)
            
            with open(ENV_CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(env_config, f, ensure_ascii=False, indent=2)
            logger.info(f"Env config saved to {ENV_CONFIG_FILE}")
            return True
        except Exception as e:
            logger.error(f"Failed to save env config: {e}")
            return False
    
    def _default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "player": {
                "name": "",
                "gender": "ë‚¨ì„±"
            },
            "character": {
                "name": "ì˜ˆë‚˜",
                "age": 21,
                "gender": "ì—¬ì„±",
                "appearance": "korean beauty, short hair, brown eyes, cute face, casual outfit",
                "personality": "ë°ê³  í™œë°œí•˜ì§€ë§Œ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ ì•ì—ì„œëŠ” ìˆ˜ì¤ìŒì´ ë§ìŒ"
            },
            "initial_stats": {
                "P": 50.0,
                "A": 40.0,
                "D": 40.0,
                "I": 20.0,
                "T": 50.0,
                "Dep": 0.0
            },
            "initial_context": "",
            "initial_background": "college library table, evening light",
            "llm_settings": {
                "provider": "ollama",
                "ollama_model": "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                "openrouter_model": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
            },
            "comfyui_settings": {
                "server_port": 8000,
                "workflow_path": "workflows/comfyui_zit.json",
                "model_name": "Zeniji_mix_ZiT_v1.safetensors",
                "steps": 9,
                "cfg": 1,
                "sampler_name": "euler",
                "scheduler": "simple"
            }
        }
    
    def save_config(self, config_data: Dict) -> bool:
        """ì„¤ì • íŒŒì¼ ì €ì¥ (í•˜ìœ„ í˜¸í™˜ì„±ìš©)"""
        try:
            with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Config saved to {CONFIG_FILE}")
            return True
        except Exception as e:
            logger.error(f"Failed to save config: {e}")
            return False
    
    def get_character_files(self) -> list:
        """character í´ë”ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            CHARACTER_DIR.mkdir(exist_ok=True)
            files = sorted([f.stem for f in CHARACTER_DIR.glob("*.json")])
            return files
        except Exception as e:
            logger.error(f"Failed to get character files: {e}")
            return []
    
    def save_character_config(self, config_data: Dict, filename: str) -> bool:
        """character í´ë”ì— ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            CHARACTER_DIR.mkdir(exist_ok=True)
            
            # íŒŒì¼ëª…ì— .jsonì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if not filename.endswith('.json'):
                filename = f"{filename}.json"
            
            file_path = CHARACTER_DIR / filename
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Character config saved to {file_path}")
            return True
        except Exception as e:
            logger.error(f"Failed to save character config: {e}")
            return False
    
    def load_character_config(self, filename: str) -> Dict:
        """character í´ë”ì—ì„œ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            # íŒŒì¼ëª…ì— .jsonì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if not filename.endswith('.json'):
                filename = f"{filename}.json"
            
            file_path = CHARACTER_DIR / filename
            
            if not file_path.exists():
                logger.warning(f"Character file not found: {file_path}")
                return self._default_config()
            
            with open(file_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return self._sanitize_config(config)
        except Exception as e:
            logger.error(f"Failed to load character config: {e}")
            return self._default_config()
    
    def get_scenario_files(self) -> list:
        """scenarios í´ë”ì˜ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            SCENARIOS_DIR.mkdir(exist_ok=True)
            files = sorted([f.stem for f in SCENARIOS_DIR.glob("*.json")])
            return files
        except Exception as e:
            logger.error(f"Failed to get scenario files: {e}")
            return []
    
    def save_scenario(self, scenario_data: dict, scenario_name: str) -> bool:
        """ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (JSON í˜•ì‹) - ëŒ€í™” + ìƒíƒœ ì •ë³´ í¬í•¨"""
        try:
            SCENARIOS_DIR.mkdir(exist_ok=True)
            
            # íŒŒì¼ëª…ì— .jsonì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if not scenario_name.endswith('.json'):
                scenario_name = f"{scenario_name}.json"
            
            file_path = SCENARIOS_DIR / scenario_name
            
            # conversation í•„í„°ë§ (ë¹ˆ content ì œê±°)
            if "conversation" in scenario_data:
                filtered_conversation = []
                for item in scenario_data["conversation"]:
                    content = item.get("content", "")
                    # contentê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                    if isinstance(content, str) and content.strip():
                        filtered_conversation.append(item)
                    elif isinstance(content, list):
                        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        text_parts = [part.get('text', '') if isinstance(part, dict) else str(part) for part in content]
                        text = ''.join(text_parts).strip()
                        if text:
                            item["content"] = text
                            filtered_conversation.append(item)
                
                scenario_data["conversation"] = filtered_conversation
                
                if not filtered_conversation:
                    logger.warning("No conversation content to save")
                    return False
            
            logger.info(f"Saving scenario to {file_path}")
            logger.info(f"  - Conversation: {len(scenario_data.get('conversation', []))} messages")
            logger.info(f"  - State: {scenario_data.get('state') is not None}")
            logger.info(f"  - Context: {scenario_data.get('context') is not None}")
            
            # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(scenario_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Scenario saved to {file_path}")
            return True
        except Exception as e:
            logger.error(f"Failed to save scenario: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def load_scenario(self, scenario_name: str) -> dict:
        """ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê¸° (JSON í˜•ì‹) - ëŒ€í™” + ìƒíƒœ ì •ë³´ í¬í•¨"""
        try:
            # íŒŒì¼ëª…ì— .jsonì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if not scenario_name.endswith('.json'):
                scenario_name = f"{scenario_name}.json"
            
            file_path = SCENARIOS_DIR / scenario_name
            
            if not file_path.exists():
                logger.warning(f"Scenario file not found: {file_path}")
                return {}
            
            with open(file_path, 'r', encoding='utf-8') as f:
                scenario_data = json.load(f)
            
            # í•˜ìœ„ í˜¸í™˜ì„±: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ë©´ dictë¡œ ë³€í™˜
            if isinstance(scenario_data, list):
                scenario_data = {"conversation": scenario_data}
            
            logger.info(f"Scenario loaded from {file_path}")
            logger.info(f"  - Conversation: {len(scenario_data.get('conversation', []))} messages")
            logger.info(f"  - State: {scenario_data.get('state') is not None}")
            logger.info(f"  - Context: {scenario_data.get('context') is not None}")
            
            return scenario_data
        except Exception as e:
            logger.error(f"Failed to load scenario: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {}
    
    def apply_preset(self, preset_name: str) -> Tuple[float, float, float, float, float, float, str, str]:
        """í”„ë¦¬ì…‹ ì ìš© - ëª¨ë“  ìˆ˜ì¹˜ê°€ í™•ì‹¤íˆ ìˆ«ìê°€ ë˜ë„ë¡ ë³´ì¥"""
        preset = PRESETS.get(preset_name, {})
        # get(key, default)ë¥¼ ì¨ë„ ë˜ì§€ë§Œ, í˜¹ì‹œ Noneì´ ë“¤ì–´ìˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ or ì²˜ë¦¬
        return (
            float(preset.get("P") or 50.0),
            float(preset.get("A") or 40.0),
            float(preset.get("D") or 40.0),
            float(preset.get("I") or 20.0),
            float(preset.get("T") or 50.0),
            float(preset.get("Dep") or 0.0),
            str(preset.get("appearance") or ""),
            str(preset.get("personality") or "")
        )
    
    def validate_and_start(
        self,
        player_name, player_gender,
        char_name, char_age, char_gender,
        appearance, personality,
        p_val, a_val, d_val, i_val, t_val, dep_val,
        initial_context, initial_background
    ) -> Tuple[str, str, list, str, str, str, str, str, str]:
        """ì„¤ì • ê²€ì¦ ë° ì‹œì‘ (ì²« ëŒ€í™” ìë™ ìƒì„±)"""
        # Slider ê°’ë“¤ì´ Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        p_val = p_val if p_val is not None else 50.0
        a_val = a_val if a_val is not None else 40.0
        d_val = d_val if d_val is not None else 40.0
        i_val = i_val if i_val is not None else 20.0
        t_val = t_val if t_val is not None else 50.0
        dep_val = dep_val if dep_val is not None else 0.0
        char_age = char_age if char_age is not None else 21
        
        # ìµœëŒ€ê°’ ê²€ì¦ (70 ì œí•œ)
        max_val = 70.0
        stats = {"P": p_val, "A": a_val, "D": d_val, "I": i_val, "T": t_val, "Dep": dep_val}
        exceeded = [k for k, v in stats.items() if v > max_val]
        
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        empty_result = (
            "âš ï¸ ê²½ê³ : ë‹¤ìŒ ìˆ˜ì¹˜ê°€ 70ì„ ì´ˆê³¼í•©ë‹ˆë‹¤: " + ", ".join(exceeded) if exceeded else "âŒ ì˜¤ë¥˜ ë°œìƒ",
            gr.Tabs(selected=None),
            [], "", "", None, "", "", ""
        )
        
        if exceeded:
            return empty_result
        
        # ì„¤ì • ë°ì´í„° êµ¬ì„±
        config_data = {
            "player": {
                "name": player_name or "",
                "gender": player_gender or "ë‚¨ì„±"
            },
            "character": {
                "name": char_name or "ì˜ˆë‚˜",
                "age": int(char_age) if char_age else 21,
                "gender": char_gender or "ì—¬ì„±",
                "appearance": appearance or "",
                "personality": personality or ""
            },
            "initial_stats": {
                "P": float(p_val),
                "A": float(a_val),
                "D": float(d_val),
                "I": float(i_val),
                "T": float(t_val),
                "Dep": float(dep_val)
            },
            "initial_context": initial_context or "",
            "initial_background": initial_background or "college library table, evening light"
        }
        
        # ì €ì¥í•˜ì§€ ì•Šê³  ë°”ë¡œ ì‹œì‘ (íŒŒì¼ ì €ì¥ì€ save ë²„íŠ¼ìœ¼ë¡œ ë³„ë„ ì²˜ë¦¬)
        
        # ëª¨ë¸ ë¡œë“œ
        status_msg, success = self.load_model()
        if not success:
            return (f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status_msg}", gr.Tabs(selected=None), [], "", "", None, "", "", "")
        
        # Brain ì´ˆê¸°í™” ë° ì„¤ì • ì ìš©
        try:
            # LLM ì„¤ì • ì½ê¸° (í™˜ê²½ì„¤ì •ì—ì„œ)
            env_config = self.load_env_config()
            llm_settings = env_config.get("llm_settings", {})
            
            # í™˜ê²½ì„¤ì •ì—ì„œ provider ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: ollama)
            provider = llm_settings.get("provider", "ollama")
            
            # OpenRouter API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
            openrouter_api_key = self._load_openrouter_api_key()
            
            # ì„¤ì •ëœ providerì— ë”°ë¼ ê²€ì¦ ë° í´ë°± ì²˜ë¦¬
            if provider == "openrouter":
                if not openrouter_api_key or not openrouter_api_key.strip():
                    logger.warning("í™˜ê²½ì„¤ì •ì—ì„œ OpenRouterê°€ ì„ íƒë˜ì—ˆì§€ë§Œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Ollamaë¡œ í´ë°±í•©ë‹ˆë‹¤.")
                    provider = "ollama"
                    llm_settings["provider"] = "ollama"
                else:
                    logger.info("í™˜ê²½ì„¤ì •ì— ë”°ë¼ OpenRouterë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                logger.info("í™˜ê²½ì„¤ì •ì— ë”°ë¼ Ollamaë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
            openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
            
            if self.brain is None:
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain = Brain(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            
            # ì´ˆê¸° ì„¤ì • ì •ë³´ ì „ë‹¬
            self.brain.set_initial_config(config_data)
            
            # ì´ˆê¸° ìƒíƒœ ì ìš©
            self.brain.state.P = config_data["initial_stats"]["P"]
            self.brain.state.A = config_data["initial_stats"]["A"]
            self.brain.state.D = config_data["initial_stats"]["D"]
            self.brain.state.I = config_data["initial_stats"]["I"]
            self.brain.state.T = config_data["initial_stats"]["T"]
            self.brain.state.Dep = config_data["initial_stats"]["Dep"]
            self.brain.state.current_background = config_data["initial_background"]
            self.brain.state.clamp()
            
            logger.info("Initial configuration applied to Brain")
        except Exception as e:
            logger.error(f"Failed to apply config: {e}")
            return (f"âŒ ì„¤ì • ì ìš© ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected=None), [], "", "", None, "", "", "")
        
        # ì²« ëŒ€í™” ìë™ ìƒì„±
        try:
            logger.info("Generating first dialogue automatically...")
            history, output_text, stats_text, image, choices_text, thought_text, action_text, radar_chart = self.process_turn("ëŒ€í™” ì‹œì‘", [])
            
            # ì²« í™”ë©´ ì´ë¯¸ì§€ ìƒì„± (appearance + background)
            initial_image = None
            if config.IMAGE_MODE_ENABLED:
                try:
                    # ComfyClient ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
                    if self.comfy_client is None:
                        # ComfyUI ì„¤ì • ë¡œë“œ
                        env_config = self.load_env_config()
                        comfyui_settings = env_config.get("comfyui_settings", {})
                        server_port = comfyui_settings.get("server_port", 8000)
                        workflow_path = comfyui_settings.get("workflow_path", "workflows/comfyui_zit.json")
                        model_name = comfyui_settings.get("model_name", "Zeniji_mix_ZiT_v1.safetensors")
                        steps = comfyui_settings.get("steps", 9)
                        cfg = comfyui_settings.get("cfg", 1.0)
                        sampler_name = comfyui_settings.get("sampler_name", "euler")
                        scheduler = comfyui_settings.get("scheduler", "simple")
                        server_address = f"127.0.0.1:{server_port}"
                        self.comfy_client = ComfyClient(
                            server_address=server_address,
                            workflow_path=workflow_path,
                            model_name=model_name,
                            steps=steps,
                            cfg=cfg,
                            sampler_name=sampler_name,
                            scheduler=scheduler
                        )
                        logger.info(f"ComfyClient initialized: {server_address}, workflow: {workflow_path}, model: {model_name}, steps: {steps}, cfg: {cfg}, sampler: {sampler_name}, scheduler: {scheduler}")
                    
                    # appearanceì™€ backgroundë¥¼ ì¡°í•©í•´ì„œ ì´ë¯¸ì§€ ìƒì„±
                    appearance = config_data["character"].get("appearance", "")
                    char_age = config_data["character"].get("age", 21)
                    background = config_data.get("initial_background", "college library table, evening light")
                    
                    # appearanceì— ë‚˜ì´ ì¶”ê°€ (ì´ë¯¸ì§€ ìƒì„±ìš©)
                    if appearance and f"{char_age} years old" not in appearance.lower():
                        appearance = f"{char_age} years old, {appearance}".strip()
                    elif not appearance:
                        appearance = f"{char_age} years old"
                    
                    # visual_prompt ìƒì„±: backgroundë¥¼ í¬í•¨í•œ ì‹œê°ì  ë¬˜ì‚¬
                    visual_prompt = f"background: {background}, expression: neutral, looking at viewer"
                    
                    logger.info(f"Generating initial image with appearance: {appearance[:50]}... and background: {background}")
                    image_bytes = self.comfy_client.generate_image(
                        visual_prompt=visual_prompt,
                        appearance=appearance,
                        seed=-1
                    )
                    
                    if image_bytes:
                        # PIL Imageë¡œ ë³€í™˜
                        initial_image = Image.open(io.BytesIO(image_bytes))
                        # í˜„ì¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
                        self.current_image = initial_image
                        logger.info("Initial image generated successfully")
                    else:
                        logger.warning("Failed to generate initial image")
                except Exception as e:
                    logger.error(f"Failed to generate initial image: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
            
            status_msg = "âœ… ì„¤ì • ì €ì¥ ë° ì²« ëŒ€í™” ìƒì„± ì™„ë£Œ!"
            # íƒ­ ì „í™˜: chat_tabì˜ idë¥¼ ì‚¬ìš©
            return (status_msg, gr.Tabs(selected="chat_tab"), history, output_text, stats_text, initial_image, choices_text, thought_text, action_text, radar_chart)
        except Exception as e:
            logger.error(f"Failed to generate first dialogue: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return (f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ ì²« ëŒ€í™” ìƒì„± ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected="chat_tab"), [], "", "", None, "", "", "", None)
    
    def load_model(self) -> Tuple[str, bool]:
        """ëª¨ë¸ ë¡œë“œ (ì„¤ì •ì—ì„œ LLM provider ì •ë³´ ì½ì–´ì„œ ì´ˆê¸°í™”)"""
        if self.model_loaded and self.brain is not None:
            return "ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.", True
        
        try:
            # ì„¤ì •ì—ì„œ LLM ì„¤ì • ì½ê¸°
            env_config = self.load_env_config()
            llm_settings = env_config.get("llm_settings", {})
            provider = llm_settings.get("provider", "ollama")
            ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
            openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
            # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
            openrouter_api_key = self._load_openrouter_api_key()
            
            # Brain ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼ MemoryManagerë„ ì´ˆê¸°í™”)
            if self.brain is None:
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain = Brain(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            else:
                # Brainì´ ì´ë¯¸ ìˆìœ¼ë©´ memory_managerë§Œ ì¬ì´ˆê¸°í™”
                model_name = ollama_model if provider == "ollama" else openrouter_model
                api_key = openrouter_api_key if provider == "openrouter" else None
                self.brain.memory_manager = MemoryManager(
                    dev_mode=self.dev_mode,
                    provider=provider,
                    model_name=model_name,
                    api_key=api_key
                )
            
            logger.info(f"Brain initialized with {provider.upper()}, loading model...")
            
            # ëª¨ë¸ ë¡œë“œ ì‹œë„ (OpenRouter ì‹¤íŒ¨ ì‹œ Ollamaë¡œ í´ë°±)
            result = self.brain.memory_manager.load_model()
            if result is None and provider == "openrouter":
                logger.warning("OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„...")
                # Ollamaë¡œ í´ë°±
                self.brain.memory_manager = MemoryManager(
                    dev_mode=self.dev_mode,
                    provider="ollama",
                    model_name=ollama_model
                )
                result = self.brain.memory_manager.load_model()
                if result is None:
                    return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„í–ˆìœ¼ë‚˜ Ollamaë„ ì—°ê²° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", False
                self.model_loaded = True
                logger.info("Model loaded successfully (Ollama fallback)")
                return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°±í•˜ì—¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!", True
            
            if result is None:
                raise RuntimeError("ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            self.model_loaded = True
            logger.info("Model loaded successfully")
            return f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({provider.upper()})", True
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", False
    
    def create_radar_chart(self, stats: Dict[str, float], deltas: Dict[str, float] = None) -> go.Figure:
        """6ì¶• ìˆ˜ì¹˜ë¥¼ ìœ„í•œ radar chart ìƒì„±"""
        categories = ['P (ì¾Œë½)', 'A (ê°ì„±)', 'D (ì§€ë°°)', 'I (ì¹œë°€)', 'T (ì‹ ë¢°)', 'Dep (ì˜ì¡´)']
        keys = ['P', 'A', 'D', 'I', 'T', 'Dep']
        
        values = [stats.get(key, 0.0) for key in keys]
        
        fig = go.Figure()
        
        # ë©”ì¸ ê°’
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name='í˜„ì¬ ìˆ˜ì¹˜',
            line_color='rgb(32, 201, 151)',
            fillcolor='rgba(32, 201, 151, 0.3)'
        ))
        
        # Deltaê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if deltas:
            delta_values = [deltas.get(key, 0.0) for key in keys]
            # Deltaë¥¼ í˜„ì¬ ê°’ì— ë”í•œ ê°’ìœ¼ë¡œ í‘œì‹œ (ë³€í™”ëŸ‰ ì‹œê°í™”)
            delta_display = [values[i] + delta_values[i] for i in range(len(values))]
            fig.add_trace(go.Scatterpolar(
                r=delta_display,
                theta=categories,
                fill='toself',
                name='ë³€í™” í›„',
                line_color='rgb(255, 99, 71)',
                fillcolor='rgba(255, 99, 71, 0.2)',
                line_dash='dash'
            ))
        
        fig.update_layout(
            polar=dict(
                domain=dict(x=[0.05, 0.95], y=[0.05, 0.95]),  # ì°¨íŠ¸ ë³¸ì²´ë¥¼ ë¯¸ì„¸í•˜ê²Œ ì¶•ì†Œ
                radialaxis=dict(
                    visible=True,
                    range=[0, 100],
                    tickfont=dict(size=9)
                ),
                angularaxis=dict(
                    tickfont=dict(size=10)
                )
            ),
            showlegend=False,
            height=320,
            width=320,  # ì„¸ë¡œê°€ ê¸´ ë°•ìŠ¤ë¼ë©´ ê°€ë¡œí­ë„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
            margin=dict(l=50, r=50, t=40, b=40)  # ì¢Œìš° ì—¬ë°±ì„ ë” í™•ë³´
        )
        
        return fig
    
    def process_turn(self, user_input: str, history: list) -> Tuple[list, str, str, str, str, str, str, Any]:
        """í„´ ì²˜ë¦¬"""
        if not user_input.strip():
            return history, "", "", None, "", "", "", None
        
        if self.brain is None:
            return history, "**ì˜¤ë¥˜**: Brainì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "", None, "", "", "", None
        
        try:
            response = self.brain.generate_response(user_input)
        except Exception as e:
            logger.error(f"Turn processing failed: {e}")
            return history, f"**ì˜¤ë¥˜ ë°œìƒ**: {str(e)}", "", None, "", "", ""
        
        # ì‘ë‹µ íŒŒì‹±
        speech = response.get("speech", "")
        thought = response.get("thought", "")
        action_speech = response.get("action_speech", "")
        emotion = response.get("emotion", "neutral")
        stats = response.get("stats", {})
        mood = response.get("mood", "Neutral")
        relationship = response.get("relationship_status", "Stranger")
        gacha_tier = response.get("gacha_tier", "normal")  # ë‚´ë¶€ ì‹œìŠ¤í…œ ìš©ì–´
        multiplier = response.get("multiplier", 1.0)
        final_delta = response.get("final_delta", {})
        new_badge = response.get("new_badge")
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history = history or []
        history = list(history)
        history.append({"role": "user", "content": user_input})
        history.append({"role": "assistant", "content": speech})
        
        # ì¶œë ¥ í…ìŠ¤íŠ¸
        output_lines = [
            f"**{speech}**",
            "",
            f"*ì†ë§ˆìŒ: {thought}*",
            "",
            f"ê°ì •: {emotion} | ê¸°ë¶„: {mood} | ê´€ê³„: {relationship}"
        ]
        
        if gacha_tier != "normal":
            tier_emoji = {"jackpot": "ğŸ°", "surprise": "âœ¨", "critical": "ğŸ’¥"}.get(gacha_tier, "ğŸ²")
            # ì‚¬ìš©ìì—ê²ŒëŠ” "ë°˜ì‘ ì •ë„"ë¡œ í‘œì‹œ
            reaction_level = {"jackpot": "ê·¹ì§„í•œ ë°˜ì‘", "surprise": "ë†€ë¼ìš´ ë°˜ì‘", "critical": "ê°•ë ¬í•œ ë°˜ì‘"}.get(gacha_tier, "íŠ¹ë³„í•œ ë°˜ì‘")
            output_lines.append(f"{tier_emoji} **{reaction_level}** (ë°°ìœ¨: x{multiplier:.1f})")
        
        if new_badge:
            output_lines.append(f"ğŸ† **ë±ƒì§€ íšë“: {new_badge}**")
        
        delta_parts = []
        for key, value in final_delta.items():
            if value != 0:
                sign = "+" if value > 0 else ""
                color = "green" if value > 0 else "red"
                delta_parts.append(f"<span style='color: {color}'>{key}: {sign}{value:.1f}</span>")
        
        if delta_parts:
            output_lines.append(f"ë³€í™”: {' | '.join(delta_parts)}")
        
        output_text = "\n".join(output_lines)
        
        def format_delta(key: str) -> str:
            delta_value = final_delta.get(key, 0)
            if delta_value > 0:
                return f'<span style="color: blue;">(+{delta_value:.0f})</span>'
            elif delta_value < 0:
                return f'<span style="color: red;">({delta_value:.0f})</span>'
            else:
                return '<span style="color: black;">(0)</span>'
        
        # ë°˜ì‘ ì •ë„ í‘œì‹œ (ì „êµ¬ ì•„ì´ì½˜)
        def format_reaction_indicators(tier: str) -> str:
            """ë°˜ì‘ ì •ë„ì— ë”°ë¼ ì „êµ¬/ë²ˆê°œ/í­ë°œ ì•„ì´ì½˜ í‘œì‹œ"""
            if tier == "jackpot":
                # í­ë°œ ì´ëª¨í‹°ì½˜ 4ê°œ
                return "ğŸ’¥ ğŸ’¥ ğŸ’¥ ğŸ’¥"
            elif tier == "surprise":
                # ë²ˆê°œ 3ê°œ, êº¼ì§„ ì „êµ¬ 1ê°œ
                return "âš¡ âš¡ âš¡ âš«"
            elif tier == "critical":
                # ë…¸ë€ ì „êµ¬ 2ê°œ, êº¼ì§„ ì „êµ¬ 2ê°œ
                return "ğŸ’¡ ğŸ’¡ âš« âš«"
            else:  # normal
                # ë…¸ë€ ì „êµ¬ 1ê°œ, êº¼ì§„ ì „êµ¬ 3ê°œ
                return "ğŸ’¡ âš« âš« âš«"
        
        reaction_indicators = format_reaction_indicators(gacha_tier)
        
        # Radar chart ìƒì„± (ì´ì „ ì°¨íŠ¸ê°€ ìˆìœ¼ë©´ ë¨¼ì € ë°˜í™˜í•˜ê³ , ìƒˆ ì°¨íŠ¸ ìƒì„± í›„ ì—…ë°ì´íŠ¸)
        # ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜í•˜ì—¬ ë¡œë”© ì¤‘ì—ë„ ì°¨íŠ¸ê°€ ë³´ì´ë„ë¡ í•¨
        if self.current_chart is not None:
            # ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜ (ì„ì‹œ)
            radar_chart = self.current_chart
        else:
            # ì²« ì°¨íŠ¸ ìƒì„± (ë¹ ë¥´ê²Œ ìƒì„±)
            radar_chart = self.create_radar_chart(stats, final_delta)
        
        # ìƒˆ ì°¨íŠ¸ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì—…ë°ì´íŠ¸ë  ì˜ˆì •)
        new_radar_chart = self.create_radar_chart(stats, final_delta)
        self.current_chart = new_radar_chart  # ë‹¤ìŒ ë²ˆì„ ìœ„í•´ ì €ì¥
        
        # ì‘ì€ ê¸€ì”¨ë¡œ 6ì¶• ìˆ˜ì¹˜ì™€ delta í‘œì‹œ (2ì—´ ë ˆì´ì•„ì›ƒ)
        stats_text = f"""
<div style="font-size: 0.85em; color: #666;">
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
<div>
<strong>6ì¶• ìˆ˜ì¹˜:</strong><br>
P (ì¾Œë½): {stats.get('P', 0):.0f} {format_delta('P')}<br>
A (ê°ì„±): {stats.get('A', 0):.0f} {format_delta('A')}<br>
D (ì§€ë°°): {stats.get('D', 0):.0f} {format_delta('D')}<br>
</div>
<div>
<strong>ë³€í™”ëŸ‰:</strong><br>
I (ì¹œë°€): {stats.get('I', 0):.0f} {format_delta('I')}<br>
T (ì‹ ë¢°): {stats.get('T', 0):.0f} {format_delta('T')}<br>
Dep (ì˜ì¡´): {stats.get('Dep', 0):.0f} {format_delta('Dep')}<br>
</div>
</div>
<br>
<strong>ë°˜ì‘ ì •ë„:</strong> {reaction_indicators} (x{multiplier:.1f})<br>
<strong>ê´€ê³„:</strong> {relationship} | <strong>ê¸°ë¶„:</strong> {mood}<br>
<strong>ë±ƒì§€:</strong> {', '.join(response.get('badges', [])) or 'None'}
</div>
"""
        
        # ì´ë¯¸ì§€ ìƒì„± (visual_change_detectedê°€ trueì´ê±°ë‚˜ 5í„´ ì´ìƒ ì§€ë‚¬ì„ ë•Œ)
        image = None
        visual_change_detected = response.get("visual_change_detected", False)
        image_generation_reasons = response.get("image_generation_reasons", [])
        new_image_generated = False  # ìƒˆ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì¶”ì 
        
        if visual_change_detected and config.IMAGE_MODE_ENABLED:
            # LLM ëª¨ë¸ offloadë¥¼ ìœ„í•œ 2ì´ˆ ëŒ€ê¸°
            import time
            logger.info("Waiting 2 second for LLM model offload...")
            time.sleep(2.0)
            
            # ì´ë¯¸ì§€ ìƒì„± ì´ìœ  ë¡œê·¸ ì¶œë ¥
            if image_generation_reasons:
                logger.info("=" * 80)
                logger.info("ğŸ¨ [ComfyUI ì´ë¯¸ì§€ ìƒì„± ì‹œì‘]")
                logger.info("=" * 80)
                logger.info("ì´ë¯¸ì§€ ìƒì„± ì´ìœ :")
                for i, reason in enumerate(image_generation_reasons, 1):
                    logger.info(f"  {i}. {reason}")
                logger.info("=" * 80)
            else:
                logger.info("ğŸ¨ [ComfyUI ì´ë¯¸ì§€ ìƒì„± ì‹œì‘] (ì´ìœ : visual_change_detected=true)")
            
            try:
                # ComfyClient ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
                if self.comfy_client is None:
                    # ComfyUI ì„¤ì • ë¡œë“œ
                    env_config = self.load_env_config()
                    comfyui_settings = env_config.get("comfyui_settings", {})
                    server_port = comfyui_settings.get("server_port", 8000)
                    workflow_path = comfyui_settings.get("workflow_path", "workflows/comfyui_zit.json")
                    model_name = comfyui_settings.get("model_name", "Zeniji_mix_ZiT_v1.safetensors")
                    steps = comfyui_settings.get("steps", 9)
                    cfg = comfyui_settings.get("cfg", 1.0)
                    sampler_name = comfyui_settings.get("sampler_name", "euler")
                    scheduler = comfyui_settings.get("scheduler", "simple")
                    server_address = f"127.0.0.1:{server_port}"
                    self.comfy_client = ComfyClient(
                        server_address=server_address,
                        workflow_path=workflow_path,
                        model_name=model_name,
                        steps=steps,
                        cfg=cfg,
                        sampler_name=sampler_name,
                        scheduler=scheduler
                    )
                    logger.info(f"ComfyClient initialized: {server_address}, workflow: {workflow_path}, model: {model_name}, steps: {steps}, cfg: {cfg}, sampler: {sampler_name}, scheduler: {scheduler}")
                
                # ì„¤ì •ì—ì„œ appearanceì™€ ë‚˜ì´ ê°€ì ¸ì˜¤ê¸°
                saved_config = self.load_config()
                appearance = saved_config["character"].get("appearance", "")
                char_age = saved_config["character"].get("age", 21)
                
                # appearanceì— ë‚˜ì´ ì¶”ê°€ (ì´ë¯¸ì§€ ìƒì„±ìš©)
                if appearance and f"{char_age} years old" not in appearance.lower():
                    appearance = f"{char_age} years old, {appearance}".strip()
                elif not appearance:
                    appearance = f"{char_age} years old"
                
                # responseì—ì„œ visual_promptì™€ background ê°€ì ¸ì˜¤ê¸°
                visual_prompt = response.get("visual_prompt", "")
                background = response.get("background", "")
                
                # visual_promptê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                if not visual_prompt:
                    visual_prompt = f"background: {background}, expression: {emotion}, looking at viewer"
                elif background and "background:" not in visual_prompt.lower():
                    # visual_promptì— backgroundê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                    visual_prompt = f"{visual_prompt}, background: {background}"
                
                logger.info(f"  appearance: {appearance[:50]}...")
                logger.info(f"  visual_prompt: {visual_prompt[:100]}...")
                
                image_bytes = self.comfy_client.generate_image(
                    visual_prompt=visual_prompt,
                    appearance=appearance,
                    seed=-1
                )
                
                if image_bytes:
                    # PIL Imageë¡œ ë³€í™˜
                    image = Image.open(io.BytesIO(image_bytes))
                    # í˜„ì¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
                    self.current_image = image
                    new_image_generated = True  # ìƒˆ ì´ë¯¸ì§€ ìƒì„±ë¨
                    logger.info("Image generated successfully")
                else:
                    logger.warning("Failed to generate image (returned None)")
            except Exception as e:
                logger.error(f"Failed to generate image: {e}")
                import traceback
                logger.error(traceback.format_exc())
                # ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨í•´ë„ ëŒ€í™”ëŠ” ê³„ì† ì§„í–‰
        
        # ìƒˆ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì´ì „ ì´ë¯¸ì§€ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë¡œë”© ì°½ ë°©ì§€)
        if not new_image_generated:
            image = self.current_image
        
        choices_text = "ë‹¤ìŒ ëŒ€ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        thought_text = f"ğŸ’­ **ì†ë§ˆìŒ**: {thought}" if thought else ""
        action_text = f"ğŸ­ **í–‰ë™**: {action_speech}" if action_speech else ""
        
        return history, output_text, stats_text, image, choices_text, thought_text, action_text, radar_chart
    
    def create_ui(self):
        """Gradio UI ìƒì„±"""
        # ì„¤ì • ë¡œë“œ
        saved_config = self.load_config()
        env_config = self.load_env_config()
        
        with gr.Blocks(title="Zeniji Emotion Simul") as demo:
            gr.Markdown("# ğŸ® Zeniji Emotion Simul")
            
            with gr.Tabs() as tabs:
                # ========== íƒ­ 1: ì´ˆê¸° ì„¤ì • ==========
                with gr.Tab("âš™ï¸ ì´ˆê¸° ì„¤ì •", id="setup_tab") as setup_tab:
                    gr.Markdown("## ìºë¦­í„° ë° ì‹œë‚˜ë¦¬ì˜¤ ì´ˆê¸° ì„¤ì •")
                    
                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ‘¤ ì£¼ì¸ê³µ ì„¤ì •")
                            player_name = gr.Textbox(
                                label="ì´ë¦„",
                                value=saved_config["player"].get("name", ""),
                                placeholder="í”Œë ˆì´ì–´ ì´ë¦„"
                            )
                            player_gender = gr.Radio(
                                label="ì„±ë³„",
                                choices=["ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€"],
                                value=saved_config["player"].get("gender", "ë‚¨ì„±")
                            )
                        
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ‘¥ ìƒëŒ€ë°© ì„¤ì •")
                            char_name = gr.Textbox(
                                label="ì´ë¦„",
                                value=saved_config["character"].get("name", "ì˜ˆë‚˜"),
                                placeholder="ìºë¦­í„° ì´ë¦„"
                            )
                            # character ì •ë³´ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
                            character_info = saved_config.get("character") or {}
                            char_age_val = character_info.get("age")
                            char_age_val = int(char_age_val) if char_age_val is not None else 21
                            
                            char_age = gr.Slider(
                                label="ë‚˜ì´",
                                minimum=18,
                                maximum=100,
                                value=char_age_val,
                                step=1
                            )
                            char_gender = gr.Radio(
                                label="ì„±ë³„",
                                choices=["ë‚¨ì„±", "ì—¬ì„±", "ê¸°íƒ€"],
                                value=saved_config["character"].get("gender", "ì—¬ì„±")
                            )
                    
                    gr.Markdown("### ğŸ“ ì™¸ëª¨ ë° ì„±ê²©")
                    appearance = gr.Textbox(
                        label="ì™¸ëª¨ ë¬˜ì‚¬ (ì˜ì–´ íƒœê·¸ í˜•ì‹)",
                        value=saved_config["character"].get("appearance", ""),
                        placeholder="ì˜ˆ: korean beauty, short hair, brown eyes, cute face, casual outfit",
                        info="ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ íƒœê·¸ë¡œ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                        lines=3,
                        max_lines=5
                    )
                    personality = gr.Textbox(
                        label="ì„±ê²© ë¬˜ì‚¬",
                        value=saved_config["character"].get("personality", ""),
                        placeholder="ì˜ˆ: ë°ê³  í™œë°œí•˜ì§€ë§Œ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ ì•ì—ì„œëŠ” ìˆ˜ì¤ìŒì´ ë§ìŒ",
                        lines=3,
                        max_lines=5
                    )
                    
                    gr.Markdown("### ğŸ“Š ì‹¬ë¦¬ ì§€í‘œ ì„¤ì • (6ì¶• ì‹œìŠ¤í…œ)")
                    gr.Markdown("ê° ìˆ˜ì¹˜ëŠ” 0~100 ì‚¬ì´ì´ë©°, ì´ˆê¸°ê°’ì€ **ìµœëŒ€ 70**ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤.")
                    
                    # initial_statsê°€ ì—†ê±°ë‚˜ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    initial_stats = saved_config.get("initial_stats") or {}
                    
                    def safe_get_stat(key: str, default: float) -> float:
                        """ì•ˆì „í•˜ê²Œ í†µê³„ ê°’ ê°€ì ¸ì˜¤ê¸° (None ì²´í¬) - ëª…ì‹œì ìœ¼ë¡œ í•œ ë²ˆ ë” or ì²˜ë¦¬"""
                        val = initial_stats.get(key)
                        if val is None:
                            return default
                        try:
                            result = float(val)
                            # NaNì´ë‚˜ inf ì²´í¬
                            if not (0 <= result <= 100):
                                return default
                            return result
                        except (ValueError, TypeError):
                            return default
                    
                    with gr.Row():
                        with gr.Column():
                            # ëª…ì‹œì ìœ¼ë¡œ or ì²˜ë¦¬ë¡œ None ë°©ì§€
                            p_val = gr.Slider(
                                label="P (Pleasure) - ì¾Œë½",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("P", 50.0) or 50.0,
                                step=1.0,
                                info="ê´€ê³„ì˜ ê¸ì •/ë¶€ì •"
                            )
                            a_val = gr.Slider(
                                label="A (Arousal) - ê°ì„±",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("A", 40.0) or 40.0,
                                step=1.0,
                                info="ê¸´ì¥ê°/ì—ë„ˆì§€"
                            )
                            d_val = gr.Slider(
                                label="D (Dominance) - ì§€ë°°",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("D", 40.0) or 40.0,
                                step=1.0,
                                info="ê´€ê³„ì˜ ì£¼ë„ê¶Œ"
                            )
                        with gr.Column():
                            i_val = gr.Slider(
                                label="I (Intimacy) - ì¹œë°€",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("I", 20.0) or 20.0,
                                step=1.0,
                                info="ì •ì„œì  ì¹œë°€ê°"
                            )
                            t_val = gr.Slider(
                                label="T (Trust) - ì‹ ë¢°",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("T", 50.0) or 50.0,
                                step=1.0,
                                info="ì‹ ë¢°ë„"
                            )
                            dep_val = gr.Slider(
                                label="Dep (Dependency) - ì˜ì¡´",
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("Dep", 0.0) or 0.0,
                                step=1.0,
                                info="ì˜ì¡´/ì§‘ì°©ë„"
                            )
                    
                    gr.Markdown("### ğŸ­ í”„ë¦¬ì…‹")
                    with gr.Row():
                        for preset_name in PRESETS.keys():
                            preset_btn = gr.Button(preset_name, variant="secondary")
                            # lambda í´ë¡œì € ë¬¸ì œ í•´ê²° ë° fn ëª…ì‹œ
                            def make_preset_handler(name):
                                def handler():
                                    return self.apply_preset(name)
                                return handler
                            preset_btn.click(
                                fn=make_preset_handler(preset_name),
                                inputs=[],
                                outputs=[p_val, a_val, d_val, i_val, t_val, dep_val, appearance, personality]
                            )
                    
                    gr.Markdown("### ğŸ“– ì´ˆê¸° ìƒí™©")
                    initial_context = gr.Textbox(
                        label="ì´ˆê¸° ìƒí™© ì„¤ëª…",
                        value=saved_config.get("initial_context", ""),
                        placeholder="ëŒ€í™”ê°€ ì‹œì‘ë˜ëŠ” ë°°ê²½ ìƒí™©ì„ ì„¤ëª…í•˜ì„¸ìš”.",
                        lines=4,
                        max_lines=6
                    )
                    initial_background = gr.Textbox(
                        label="ë°°ê²½ (ì˜ì–´)",
                        value=saved_config.get("initial_background", "college library table, evening light"),
                        placeholder="college library table, evening light",
                        info="ì´ë¯¸ì§€ ìƒì„±ìš© ë°°ê²½ ì„¤ëª… (ì˜ì–´)"
                    )
                    
                    # TODO: ëœë¤ ìƒí™© ìƒì„± ë²„íŠ¼
                    # random_context_btn = gr.Button("ğŸ² ëœë¤ ìƒí™© ìƒì„±", variant="secondary")
                    
                    setup_status = gr.Markdown("")
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
                    gr.Markdown("### ğŸ“š ëŒ€í™” ì´ì–´ê°€ê¸°")
                    with gr.Row():
                        with gr.Column(scale=2):
                            scenario_dropdown = gr.Dropdown(
                                label="ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼",
                                choices=self.get_scenario_files(),
                                value=None,
                                info="ì €ì¥ëœ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ"
                            )
                        with gr.Column(scale=1):
                            continue_chat_btn = gr.Button("ğŸ“– ëŒ€í™” ì´ì–´ê°€ê¸°", variant="secondary", size="lg")
                    
                    # Character íŒŒì¼ ê´€ë¦¬
                    with gr.Row():
                        with gr.Column(scale=2):
                            character_file_dropdown = gr.Dropdown(
                                label="ìºë¦­í„° íŒŒì¼",
                                choices=self.get_character_files(),
                                value=None,
                                info="ì €ì¥ëœ ìºë¦­í„° ì„¤ì • íŒŒì¼ ì„ íƒ"
                            )
                        with gr.Column(scale=1):
                            character_filename_input = gr.Textbox(
                                label="ì €ì¥í•  íŒŒì¼ëª…",
                                placeholder="ì˜ˆ: my_character",
                                info="íŒŒì¼ëª…ë§Œ ì…ë ¥ (í™•ì¥ì ìë™ ì¶”ê°€)"
                            )
                            overwrite_checkbox = gr.Checkbox(
                                label="ë®ì–´ì“°ê¸° í—ˆìš©",
                                value=False,
                                info="ê°™ì€ íŒŒì¼ëª…ì´ ìˆì„ ë•Œ ë®ì–´ì“°ê¸° í—ˆìš©"
                            )
                    
                    with gr.Row():
                        load_btn = gr.Button("ğŸ“‚ ë¶ˆëŸ¬ì˜¤ê¸°", variant="secondary", size="lg")
                        save_btn = gr.Button("ğŸ’¾ ì €ì¥", variant="secondary", size="lg")
                        start_btn = gr.Button("ğŸš€ ì‹œì‘", variant="primary", size="lg")
                    
                    def load_character(selected_file):
                        """ìºë¦­í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
                        if not selected_file:
                            return "âš ï¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", *([gr.update()] * 12)
                        
                        try:
                            config = self.load_character_config(selected_file)
                            
                            # UI ì—…ë°ì´íŠ¸
                            return (
                                f"âœ… {selected_file} ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!",
                                config["player"].get("name", ""),
                                config["player"].get("gender", "ë‚¨ì„±"),
                                config["character"].get("name", "ì˜ˆë‚˜"),
                                config["character"].get("age", 21),
                                config["character"].get("gender", "ì—¬ì„±"),
                                config["character"].get("appearance", ""),
                                config["character"].get("personality", ""),
                                config["initial_stats"].get("P", 50.0),
                                config["initial_stats"].get("A", 40.0),
                                config["initial_stats"].get("D", 40.0),
                                config["initial_stats"].get("I", 20.0),
                                config["initial_stats"].get("T", 50.0),
                                config["initial_stats"].get("Dep", 0.0),
                                config.get("initial_context", ""),
                                config.get("initial_background", "college library table, evening light")
                            )
                        except Exception as e:
                            logger.error(f"Failed to load character: {e}")
                            return f"âŒ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}", *([gr.update()] * 12)
                    
                    def save_character(filename, overwrite, player_name, player_gender, char_name, char_age, char_gender,
                                     appearance, personality, p_val, a_val, d_val, i_val, t_val, dep_val,
                                     initial_context, initial_background):
                        """ìºë¦­í„° ì„¤ì • ì €ì¥"""
                        if not filename or not filename.strip():
                            return "âš ï¸ íŒŒì¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", gr.Dropdown()
                        
                        try:
                            # íŒŒì¼ëª… ì •ë¦¬
                            clean_filename = filename.strip()
                            if not clean_filename.endswith('.json'):
                                clean_filename = f"{clean_filename}.json"
                            
                            # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            file_path = CHARACTER_DIR / clean_filename
                            if file_path.exists() and not overwrite:
                                return f"âš ï¸ ê²½ê³ : '{clean_filename}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. 'ë®ì–´ì“°ê¸° í—ˆìš©'ì„ ì²´í¬í•˜ê±°ë‚˜ ë‹¤ë¥¸ íŒŒì¼ëª…ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.", gr.Dropdown()
                            
                            # ì„¤ì • ë°ì´í„° êµ¬ì„±
                            config_data = {
                                "player": {
                                    "name": player_name or "",
                                    "gender": player_gender or "ë‚¨ì„±"
                                },
                                "character": {
                                    "name": char_name or "ì˜ˆë‚˜",
                                    "age": int(char_age) if char_age else 21,
                                    "gender": char_gender or "ì—¬ì„±",
                                    "appearance": appearance or "",
                                    "personality": personality or ""
                                },
                                "initial_stats": {
                                    "P": float(p_val) if p_val is not None else 50.0,
                                    "A": float(a_val) if a_val is not None else 40.0,
                                    "D": float(d_val) if d_val is not None else 40.0,
                                    "I": float(i_val) if i_val is not None else 20.0,
                                    "T": float(t_val) if t_val is not None else 50.0,
                                    "Dep": float(dep_val) if dep_val is not None else 0.0
                                },
                                "initial_context": initial_context or "",
                                "initial_background": initial_background or "college library table, evening light"
                            }
                            
                            if self.save_character_config(config_data, clean_filename):
                                # character_config.jsonë„ ë®ì–´ì“°ê¸° (ë‹¤ìŒ ì‹¤í–‰ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
                                self.save_config(config_data)
                                
                                # ë“œë¡­ë‹¤ìš´ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
                                updated_files = self.get_character_files()
                                return f"âœ… {clean_filename} ì €ì¥ ì™„ë£Œ! (character_config.jsonë„ ì—…ë°ì´íŠ¸ë¨)", gr.Dropdown(choices=updated_files, value=clean_filename.replace('.json', ''))
                            else:
                                return "âŒ ì €ì¥ ì‹¤íŒ¨", gr.Dropdown()
                        except Exception as e:
                            logger.error(f"Failed to save character: {e}")
                            return f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}", gr.Dropdown()
                    
                    load_btn.click(
                        load_character,
                        inputs=[character_file_dropdown],
                        outputs=[
                            setup_status,
                            player_name, player_gender,
                            char_name, char_age, char_gender,
                            appearance, personality,
                            p_val, a_val, d_val, i_val, t_val, dep_val,
                            initial_context, initial_background
                        ]
                    )
                    
                    save_btn.click(
                        save_character,
                        inputs=[
                            character_filename_input,
                            overwrite_checkbox,
                            player_name, player_gender,
                            char_name, char_age, char_gender,
                            appearance, personality,
                            p_val, a_val, d_val, i_val, t_val, dep_val,
                            initial_context, initial_background
                        ],
                        outputs=[setup_status, character_file_dropdown]
                    )
                    
                    def continue_chat(selected_scenario):
                        """ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ëŒ€í™” ì´ì–´ê°€ê¸°"""
                        if not selected_scenario:
                            return "âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                        
                        try:
                            # ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
                            scenario_data = self.load_scenario(selected_scenario)
                            
                            if not scenario_data or "conversation" not in scenario_data:
                                return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            history = scenario_data.get("conversation", [])
                            if not history:
                                return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ì— ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            # ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                            if not self.model_loaded:
                                status_msg, success = self.load_model()
                                if not success:
                                    return f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status_msg}", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            # ì´ˆê¸° ì„¤ì • ì •ë³´ ë³µì› (í”„ë¡¬í”„íŠ¸ì— í•„ìˆ˜)
                            if self.brain is not None and "initial_config" in scenario_data:
                                self.brain.set_initial_config(scenario_data["initial_config"])
                                logger.info("Initial config restored")
                            
                            # ìƒíƒœ ì •ë³´ ë³µì›
                            if self.brain is not None and "state" in scenario_data:
                                state_data = scenario_data["state"]
                                state = self.brain.state
                                
                                # Stats ë³µì›
                                if "stats" in state_data:
                                    stats = state_data["stats"]
                                    state.P = stats.get("P", state.P)
                                    state.A = stats.get("A", state.A)
                                    state.D = stats.get("D", state.D)
                                    state.I = stats.get("I", state.I)
                                    state.T = stats.get("T", state.T)
                                    state.Dep = stats.get("Dep", state.Dep)
                                
                                # ê´€ê³„ ìƒíƒœ ë³µì›
                                if "relationship" in state_data:
                                    state.relationship_status = state_data["relationship"]
                                
                                # ê¸°ë¶„ì€ interpret_moodë¡œ ê³„ì‚°ë˜ë¯€ë¡œ ë³µì› ë¶ˆí•„ìš” (stats ë³µì› í›„ ìë™ ê³„ì‚°ë¨)
                                # moodëŠ” ì €ì¥ë§Œ í•˜ê³  ë³µì›ì€ í•˜ì§€ ì•ŠìŒ (ê³„ì‚°ëœ ê°’ì´ë¯€ë¡œ)
                                
                                # ë±ƒì§€ ë³µì›
                                if "badges" in state_data:
                                    state.badges = set(state_data["badges"])
                                
                                # íŠ¸ë¼ìš°ë§ˆ ë ˆë²¨ ë³µì›
                                if "trauma_level" in state_data:
                                    state.trauma_level = state_data["trauma_level"]
                                
                                # í˜„ì¬ ë°°ê²½ ë³µì›
                                if "current_background" in state_data:
                                    state.current_background = state_data["current_background"]
                                
                                # ì´ í„´ ìˆ˜ ë³µì›
                                if "total_turns" in state_data:
                                    state.total_turns = state_data["total_turns"]
                                
                                # moodëŠ” interpret_moodë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                logger.info(f"State restored: relationship={state.relationship_status}, mood={calculated_mood}, badges={list(state.badges)}, background={state.current_background}, turns={state.total_turns}")
                            
                            # ë¬¸ë§¥ ì •ë³´ ë³µì› (ìµœê·¼ í„´)
                            if self.brain is not None and "context" in scenario_data:
                                context = scenario_data["context"]
                                if "recent_turns" in context and hasattr(self.brain, 'history'):
                                    # DialogueHistoryì— í„´ ì¶”ê°€
                                    for turn_data in context["recent_turns"]:
                                        from state_manager import DialogueTurn
                                        turn = DialogueTurn(
                                            player_input=turn_data.get("player_input", ""),
                                            character_response=turn_data.get("character_response", ""),
                                            emotion=turn_data.get("emotion", "neutral"),
                                            stats_delta=turn_data.get("stats_delta", {})
                                        )
                                        self.brain.history.add(turn)
                                    logger.info(f"Context restored: {len(context.get('recent_turns', []))} recent turns")
                            
                            # íˆìŠ¤í† ë¦¬ë¥¼ chatbot í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë”•ì…”ë„ˆë¦¬ í˜•ì‹ ì‚¬ìš©)
                            chatbot_history = []
                            for item in history:
                                role = item.get("role", "")
                                content = item.get("content", "")
                                if role == "user":
                                    chatbot_history.append({"role": "user", "content": content})
                                elif role == "assistant":
                                    chatbot_history.append({"role": "assistant", "content": content})
                            
                            # í˜„ì¬ ìƒíƒœë¡œ ì°¨íŠ¸ ìƒì„±
                            if self.brain is not None:
                                stats = self.brain.state.get_stats_dict()
                                current_chart = self.create_radar_chart(stats, {})
                                self.current_chart = current_chart
                            else:
                                current_chart = self.current_chart
                            
                            # í˜„ì¬ ì´ë¯¸ì§€ì™€ ì°¨íŠ¸ëŠ” ìœ ì§€
                            current_image = self.current_image
                            
                            # stats_text ìƒì„±
                            if self.brain is not None:
                                state = self.brain.state
                                stats = state.get_stats_dict()
                                
                                # moodëŠ” interpret_moodë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                stats_text = f"""
<div style="font-size: 0.85em; color: #666;">
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
<div>
<strong>6ì¶• ìˆ˜ì¹˜:</strong><br>
P (ì¾Œë½): {stats.get('P', 0):.0f}<br>
A (ê°ì„±): {stats.get('A', 0):.0f}<br>
D (ì§€ë°°): {stats.get('D', 0):.0f}<br>
</div>
<div>
<strong>ë³€í™”ëŸ‰:</strong><br>
I (ì¹œë°€): {stats.get('I', 0):.0f}<br>
T (ì‹ ë¢°): {stats.get('T', 0):.0f}<br>
Dep (ì˜ì¡´): {stats.get('Dep', 0):.0f}<br>
</div>
</div>
<br>
<strong>ê´€ê³„:</strong> {state.relationship_status} | <strong>ê¸°ë¶„:</strong> {calculated_mood}<br>
<strong>ë±ƒì§€:</strong> {', '.join(state.badges) or 'None'}
</div>
"""
                            else:
                                stats_text = ""
                            
                            return (
                                f"âœ… ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}' ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!",
                                gr.Tabs(selected="chat_tab"),
                                chatbot_history,
                                "",
                                stats_text,
                                current_image,
                                "",
                                "",
                                "",
                                current_chart
                            )
                        except Exception as e:
                            logger.error(f"Failed to continue chat: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                
                # ========== íƒ­ 2: ëŒ€í™” ==========
                with gr.Tab("ğŸ’¬ ëŒ€í™”", id="chat_tab") as chat_tab:
                    with gr.Row():
                        with gr.Column(scale=2):
                            chatbot = gr.Chatbot(label="ëŒ€í™”", height=500)
                            
                            # ì†ë§ˆìŒ: Accordionìœ¼ë¡œ ì ‘ê¸°/í¼ì¹˜ê¸° ê°€ëŠ¥í•˜ê²Œ
                            with gr.Accordion("ğŸ’­ ì†ë§ˆìŒ ë³´ê¸°", open=False, visible=True) as thought_accordion:
                                thought_display = gr.Markdown(label="", visible=True)
                            
                            action_display = gr.Markdown(label="ğŸ­ í–‰ë™", visible=True)
                            user_input = gr.Textbox(label="ì…ë ¥", placeholder="ë§ì„ ì…ë ¥í•˜ì„¸ìš”...", interactive=False)
                            submit_btn = gr.Button("ì „ì†¡", variant="primary", interactive=False)
                        
                        with gr.Column(scale=1):
                            stats_chart = gr.Plot(label="6ì¶• ìˆ˜ì¹˜", show_label=True)
                            stats_display = gr.Markdown(label="ìƒíƒœ ìƒì„¸", show_label=True)
                            image_display = gr.Image(label="ìºë¦­í„°", height=400)
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ (ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì•„ë˜, í™”ë©´ ë„ˆë¹„ ì „ì²´ ì‚¬ìš©)
                    with gr.Row():
                        scenario_save_name = gr.Textbox(
                            label="ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥",
                            placeholder="ì˜ˆ: my_scenario",
                            info="í˜„ì¬ ëŒ€í™”ë¥¼ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì €ì¥",
                            scale=3
                        )
                        save_scenario_btn = gr.Button("ğŸ’¾ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥", variant="secondary", scale=1)
                        scenario_save_status = gr.Markdown("")
                    
                    # ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°ìš© hidden state
                    image_update_trigger = gr.State(value=None)
                    
                    def on_submit(message, history):
                        if not self.model_loaded:
                            return history, "", "", "", "", None, None  # ë§ˆì§€ë§‰ ë‘ ê°œëŠ” triggerì™€ chart
                        
                        # ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜ (ë¡œë”© ì¤‘ì—ë„ ì°¨íŠ¸ê°€ ë³´ì´ë„ë¡)
                        previous_chart = self.current_chart if self.current_chart is not None else None
                        
                        new_history, output, stats, image, choices, thought, action, chart = self.process_turn(message, history)
                        
                        # imageê°€ ìƒˆë¡œ ìƒì„±ëìœ¼ë©´ triggerì— ë„£ê³ , ì•„ë‹ˆë©´ None
                        # ì°¨íŠ¸ëŠ” ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜í•˜ê³ , ìƒˆ ì°¨íŠ¸ëŠ” ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                        return new_history, "", stats, thought, action, image, previous_chart if previous_chart else chart
                    
                    def update_chart_async(history):
                        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì°¨íŠ¸ ì—…ë°ì´íŠ¸"""
                        if not self.model_loaded or not history:
                            return gr.skip()
                        
                        # ë§ˆì§€ë§‰ ëŒ€í™”ì—ì„œ stats ì¶”ì¶œí•˜ì—¬ ì°¨íŠ¸ ìƒì„±
                        try:
                            # historyì—ì„œ ë§ˆì§€ë§‰ ì‘ë‹µì˜ stats ê°€ì ¸ì˜¤ê¸°
                            # ì‹¤ì œë¡œëŠ” process_turnì—ì„œ ì´ë¯¸ ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìœ¼ë¯€ë¡œ current_chart ì‚¬ìš©
                            if self.current_chart is not None:
                                return self.current_chart
                        except:
                            pass
                        return gr.skip()
                    
                    def save_scenario_handler(scenario_name, history):
                        """ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ í•¸ë“¤ëŸ¬ (ëŒ€í™” + ìƒíƒœ ì •ë³´ í¬í•¨)"""
                        if not scenario_name or not scenario_name.strip():
                            return "âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", gr.Dropdown()
                        
                        if not history:
                            return "âš ï¸ ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.", gr.Dropdown()
                        
                        try:
                            logger.info(f"Saving scenario: {scenario_name}, history length: {len(history) if history else 0}")
                            
                            # chatbot historyë¥¼ process_turn í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            converted_history = []
                            for item in history:
                                if isinstance(item, list) and len(item) == 2:
                                    # Gradio chatbot í˜•ì‹: [user_msg, assistant_msg]
                                    user_msg, assistant_msg = item
                                    if user_msg:
                                        # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                                        if isinstance(user_msg, list):
                                            # [{'text': '...', 'type': 'text'}] í˜•ì‹
                                            text_parts = [part.get('text', '') if isinstance(part, dict) else str(part) for part in user_msg]
                                            user_msg = ''.join(text_parts)
                                        converted_history.append({"role": "user", "content": str(user_msg)})
                                    if assistant_msg:
                                        # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                                        if isinstance(assistant_msg, list):
                                            text_parts = [part.get('text', '') if isinstance(part, dict) else str(part) for part in assistant_msg]
                                            assistant_msg = ''.join(text_parts)
                                        converted_history.append({"role": "assistant", "content": str(assistant_msg)})
                                elif isinstance(item, dict):
                                    # ì´ë¯¸ dict í˜•ì‹ì¸ ê²½ìš°
                                    content = item.get("content", "")
                                    # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                                    if isinstance(content, list):
                                        text_parts = [part.get('text', '') if isinstance(part, dict) else str(part) for part in content]
                                        content = ''.join(text_parts)
                                        item["content"] = content
                                    converted_history.append(item)
                            
                            logger.info(f"Converted history length: {len(converted_history)}")
                            
                            if not converted_history:
                                return "âš ï¸ ë³€í™˜ëœ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.", gr.Dropdown()
                            
                            # Brainì—ì„œ ìƒíƒœ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                            scenario_data = {
                                "conversation": converted_history
                            }
                            
                            if self.brain is not None:
                                # í˜„ì¬ ìƒíƒœ ì •ë³´
                                state = self.brain.state
                                
                                # moodëŠ” interpret_mood í•¨ìˆ˜ë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                scenario_data["state"] = {
                                    "stats": {
                                        "P": state.P,
                                        "A": state.A,
                                        "D": state.D,
                                        "I": state.I,
                                        "T": state.T,
                                        "Dep": state.Dep
                                    },
                                    "relationship": state.relationship_status,
                                    "mood": calculated_mood,  # ê³„ì‚°ëœ mood ê°’ ì €ì¥
                                    "badges": list(state.badges) if hasattr(state, 'badges') else [],
                                    "trauma_level": state.trauma_level if hasattr(state, 'trauma_level') else 0.0,
                                    "current_background": state.current_background if hasattr(state, 'current_background') else "",
                                    "total_turns": state.total_turns if hasattr(state, 'total_turns') else 0
                                }
                                
                                # ì´ˆê¸° ì„¤ì • ì •ë³´ (í”„ë¡¬í”„íŠ¸ì— í•„ìˆ˜)
                                if hasattr(self.brain, 'initial_config') and self.brain.initial_config:
                                    scenario_data["initial_config"] = self.brain.initial_config
                                
                                # ìµœê·¼ ëŒ€í™” í„´ (ë¬¸ë§¥ ì •ë³´)
                                if hasattr(self.brain, 'history') and self.brain.history:
                                    recent_turns = []
                                    for turn in self.brain.history.turns[-5:]:  # ìµœê·¼ 5í„´
                                        if hasattr(turn, 'player_input') and hasattr(turn, 'character_response'):
                                            recent_turns.append({
                                                "player_input": turn.player_input,
                                                "character_response": turn.character_response,
                                                "emotion": getattr(turn, 'emotion', 'neutral'),
                                                "stats_delta": getattr(turn, 'stats_delta', {})
                                            })
                                    scenario_data["context"] = {
                                        "recent_turns": recent_turns
                                    }
                            
                            if self.save_scenario(scenario_data, scenario_name.strip()):
                                # ë“œë¡­ë‹¤ìš´ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
                                updated_files = self.get_scenario_files()
                                return f"âœ… {scenario_name.strip()}.json ì €ì¥ ì™„ë£Œ!", gr.Dropdown(choices=updated_files, value=scenario_name.strip())
                            else:
                                return "âŒ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ ì‹¤íŒ¨", gr.Dropdown()
                        except Exception as e:
                            logger.error(f"Failed to save scenario: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}", gr.Dropdown()
                    
                    save_scenario_btn.click(
                        save_scenario_handler,
                        inputs=[scenario_save_name, chatbot],
                        outputs=[scenario_save_status, scenario_dropdown]
                    )
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼ (ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ê°€ ì •ì˜ëœ í›„ì— ì—°ê²°)
                    continue_chat_btn.click(
                        continue_chat,
                        inputs=[scenario_dropdown],
                        outputs=[
                            setup_status, tabs,
                            chatbot, gr.Textbox(visible=False), stats_display, image_display,
                            gr.Textbox(visible=False), thought_display, action_display, stats_chart
                        ]
                    )
                    
                    def update_chart_if_needed(new_chart):
                        """ì°¨íŠ¸ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°"""
                        if new_chart is not None:
                            return new_chart
                        return gr.skip()
                    
                    def update_image_if_needed(trigger_image):
                        """íŠ¸ë¦¬ê±°ì— ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ ë°˜í™˜, ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ ì•ˆ í•¨"""
                        if trigger_image is not None:
                            return trigger_image
                        return gr.skip()  # Gradio 6.x: ì—…ë°ì´íŠ¸ ê±´ë„ˆë›°ê¸°
                    
                    # ë©”ì¸ submit - ì´ë¯¸ì§€ì™€ ì°¨íŠ¸ëŠ” ë¹„ë™ê¸°ë¡œ ì—…ë°ì´íŠ¸
                    submit_btn.click(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger, stats_chart]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display]
                    ).then(
                        update_chart_async,
                        inputs=[chatbot],
                        outputs=[stats_chart]
                    )
                    
                    user_input.submit(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger, stats_chart]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display]
                    ).then(
                        update_chart_async,
                        inputs=[chatbot],
                        outputs=[stats_chart]
                    )
                    
                    # ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ì‹œ UI í™œì„±í™”
                    def enable_chat_ui():
                        if self.model_loaded:
                            return (
                                gr.Button(interactive=True),  # submit_btn
                                gr.Textbox(interactive=True)  # user_input
                            )
                        return (
                            gr.Button(interactive=False),
                            gr.Textbox(interactive=False)
                        )
                    
                    # íƒ­ ì „í™˜ ì‹œ UI ìƒíƒœ í™•ì¸
                    chat_tab.select(
                        enable_chat_ui,
                        inputs=[],
                        outputs=[submit_btn, user_input]
                    )
                
                # ========== íƒ­ 3: í™˜ê²½ì„¤ì • ==========
                with gr.Tab("âš™ï¸ í™˜ê²½ì„¤ì •", id="settings_tab"):
                    gr.Markdown("## LLM ì„¤ì •")
                    
                    # LLM ì„¤ì • ë¡œë“œ
                    llm_settings = env_config.get("llm_settings", {})
                    provider = llm_settings.get("provider", "ollama")
                    ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
                    openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
                    # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                    openrouter_api_key = self._load_openrouter_api_key()
                    
                    llm_provider = gr.Radio(
                        label="LLM Provider",
                        choices=["ollama", "openrouter"],
                        value=provider,
                        info="ì‚¬ìš©í•  LLM ì„œë¹„ìŠ¤ ì„ íƒ"
                    )
                    
                    with gr.Group(visible=(provider == "ollama")) as ollama_group:
                        ollama_model_input = gr.Textbox(
                            label="Ollama ëª¨ë¸ ì´ë¦„",
                            value=ollama_model,
                            placeholder="ì˜ˆ: kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                            info="'ollama list' ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•œ ì •í™•í•œ ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
                        )
                    
                    with gr.Group(visible=(provider == "openrouter")) as openrouter_group:
                        openrouter_api_key_input = gr.Textbox(
                            label="OpenRouter API í‚¤",
                            value=openrouter_api_key,
                            placeholder="sk-or-v1-...",
                            type="password",
                            info="OpenRouter API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (https://openrouter.ai/keys)"
                        )
                        openrouter_model_input = gr.Textbox(
                            label="OpenRouter ëª¨ë¸",
                            value=openrouter_model,
                            placeholder="ì˜ˆ: cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
                            info="OpenRouterì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„"
                        )
                    
                    # Provider ë³€ê²½ ì‹œ UI í‘œì‹œ/ìˆ¨ê¹€
                    def update_provider_ui(selected_provider):
                        return (
                            gr.Group(visible=(selected_provider == "ollama")),
                            gr.Group(visible=(selected_provider == "openrouter"))
                        )
                    
                    llm_provider.change(
                        update_provider_ui,
                        inputs=[llm_provider],
                        outputs=[ollama_group, openrouter_group]
                    )
                    
                    settings_status = gr.Markdown("")
                    save_settings_btn = gr.Button("ğŸ’¾ ì„¤ì • ì €ì¥", variant="primary")
                    
                    def save_llm_settings(provider_val, ollama_model_val, openrouter_key_val, openrouter_model_val):
                        """LLM ì„¤ì • ì €ì¥"""
                        try:
                            env_config = self.load_env_config()
                            
                            # OpenRouter API í‚¤ëŠ” ë³„ë„ íŒŒì¼ì— ì €ì¥
                            if provider_val == "openrouter" and openrouter_key_val:
                                if not self._save_openrouter_api_key(openrouter_key_val):
                                    return "âŒ OpenRouter API í‚¤ ì €ì¥ ì‹¤íŒ¨"
                            
                            # LLM ì„¤ì • ì—…ë°ì´íŠ¸ (API í‚¤ëŠ” ì œì™¸)
                            env_config["llm_settings"] = {
                                "provider": provider_val,
                                "ollama_model": ollama_model_val or "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                                "openrouter_model": openrouter_model_val or "cognitivecomputations/dolphin-mistral-24b-venice-edition:free"
                            }
                            
                            # í™˜ê²½ì„¤ì • ì €ì¥
                            if self.save_env_config(env_config):
                                # Brain ì¬ì´ˆê¸°í™” (ìƒˆ ì„¤ì • ì ìš©)
                                try:
                                    if self.brain is not None:
                                        # ê¸°ì¡´ Brainì˜ memory_managerë¥¼ ìƒˆ ì„¤ì •ìœ¼ë¡œ ì¬ì´ˆê¸°í™”
                                        llm_settings = env_config["llm_settings"]
                                        # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                                        api_key = self._load_openrouter_api_key() if llm_settings["provider"] == "openrouter" else None
                                        self.brain.memory_manager = MemoryManager(
                                            dev_mode=self.dev_mode,
                                            provider=llm_settings["provider"],
                                            model_name=llm_settings["ollama_model"] if llm_settings["provider"] == "ollama" else llm_settings["openrouter_model"],
                                            api_key=api_key
                                        )
                                        
                                        # ëª¨ë¸ ë¡œë“œ ì‹œë„ (OpenRouter ì‹¤íŒ¨ ì‹œ Ollamaë¡œ í´ë°±)
                                        result = self.brain.memory_manager.load_model()
                                        if result is None and llm_settings["provider"] == "openrouter":
                                            logger.warning("OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„...")
                                            # Ollamaë¡œ í´ë°±
                                            env_config["llm_settings"]["provider"] = "ollama"
                                            self.brain.memory_manager = MemoryManager(
                                                dev_mode=self.dev_mode,
                                                provider="ollama",
                                                model_name=llm_settings["ollama_model"]
                                            )
                                            result = self.brain.memory_manager.load_model()
                                            if result is None:
                                                return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„í–ˆìœ¼ë‚˜ Ollamaë„ ì—°ê²° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                                            # í´ë°± ì„¤ì • ì €ì¥
                                            self.save_env_config(env_config)
                                            return "âš ï¸ OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°±í•˜ì—¬ ì„¤ì • ì €ì¥ ì™„ë£Œ."
                                        
                                        self.model_loaded = (result is not None)
                                        if self.model_loaded:
                                            return f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ! ({llm_settings['provider'].upper()} ì—°ê²° ì„±ê³µ)"
                                        else:
                                            return f"âš ï¸ ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ {llm_settings['provider'].upper()} ì—°ê²° ì‹¤íŒ¨"
                                    else:
                                        return "âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ! (ë‹¤ìŒ ì‹œì‘ ì‹œ ì ìš©ë©ë‹ˆë‹¤)"
                                except Exception as e:
                                    logger.error(f"Failed to reinitialize Brain: {e}")
                                    return f"âœ… ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ ëª¨ë¸ ì¬ì—°ê²° ì‹¤íŒ¨: {str(e)}"
                            else:
                                return "âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨"
                        except Exception as e:
                            logger.error(f"Failed to save LLM settings: {e}")
                            return f"âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}"
                    
                    save_settings_btn.click(
                        save_llm_settings,
                        inputs=[llm_provider, ollama_model_input, openrouter_api_key_input, openrouter_model_input],
                        outputs=[settings_status]
                    )
                    
                    gr.Markdown("---")
                    gr.Markdown("## ComfyUI ì„¤ì •")
                    
                    # ComfyUI ì„¤ì • ë¡œë“œ
                    comfyui_settings = env_config.get("comfyui_settings", {})
                    comfyui_port = comfyui_settings.get("server_port", 8000)
                    workflow_path = comfyui_settings.get("workflow_path", "workflows/comfyui_zit.json")
                    comfyui_model = comfyui_settings.get("model_name", "Zeniji_mix_ZiT_v1.safetensors")
                    comfyui_steps = comfyui_settings.get("steps", 9)
                    comfyui_cfg = comfyui_settings.get("cfg", 1)
                    comfyui_sampler = comfyui_settings.get("sampler_name", "euler")
                    comfyui_scheduler = comfyui_settings.get("scheduler", "simple")
                    
                    # workflows í´ë”ì˜ .json íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    workflows_dir = Path("workflows")
                    workflow_files = []
                    if workflows_dir.exists():
                        workflow_files = sorted([f.name for f in workflows_dir.glob("*.json")])
                    
                    if not workflow_files:
                        workflow_files = ["comfyui_zit.json"]  # ê¸°ë³¸ê°’
                    
                    # í˜„ì¬ ì„ íƒëœ ì›Œí¬í”Œë¡œìš° íŒŒì¼ëª… ì¶”ì¶œ
                    current_workflow = Path(workflow_path).name if workflow_path else workflow_files[0]
                    if current_workflow not in workflow_files:
                        current_workflow = workflow_files[0]
                    
                    with gr.Row():
                        with gr.Column():
                            comfyui_port_input = gr.Number(
                                label="ComfyUI ì„œë²„ í¬íŠ¸",
                                value=comfyui_port,
                                minimum=1,
                                maximum=65535,
                                step=1,
                                info="ComfyUI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ í¬íŠ¸ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 8000)"
                            )
                            comfyui_workflow_input = gr.Dropdown(
                                label="ì›Œí¬í”Œë¡œìš° íŒŒì¼",
                                value=current_workflow,
                                choices=workflow_files,
                                info="workflows í´ë”ì—ì„œ ì‚¬ìš©í•  ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì„ íƒ"
                            )
                            comfyui_model_input = gr.Textbox(
                                label="ComfyUI ëª¨ë¸ ì´ë¦„",
                                value=comfyui_model,
                                placeholder="ì˜ˆ: Zeniji_mix_ZiT_v1.safetensors",
                                info="ComfyUIì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ ì´ë¦„ (í™•ì¥ì í¬í•¨)"
                            )
                        with gr.Column():
                            comfyui_steps_input = gr.Number(
                                label="Steps (ìƒì„± ë‹¨ê³„ ìˆ˜)",
                                value=comfyui_steps,
                                minimum=1,
                                maximum=100,
                                step=1,
                                info="ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ ìˆ˜ (ê¸°ë³¸ê°’: 9)"
                            )
                            comfyui_cfg_input = gr.Number(
                                label="CFG Scale (í”„ë¡¬í”„íŠ¸ ê°•ë„)",
                                value=comfyui_cfg,
                                minimum=0.1,
                                maximum=20.0,
                                step=0.1,
                                info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ë„ (ê¸°ë³¸ê°’: 1)"
                            )
                            comfyui_sampler_input = gr.Textbox(
                                label="Sampler (ìƒ˜í”ŒëŸ¬)",
                                value=comfyui_sampler,
                                placeholder="ì˜ˆ: euler",
                                info="ì´ë¯¸ì§€ ìƒì„± ìƒ˜í”ŒëŸ¬ ì´ë¦„ (ê¸°ë³¸ê°’: euler)"
                            )
                            comfyui_scheduler_input = gr.Textbox(
                                label="Scheduler (ìŠ¤ì¼€ì¤„ëŸ¬)",
                                value=comfyui_scheduler,
                                placeholder="ì˜ˆ: simple",
                                info="ìŠ¤ì¼€ì¤„ëŸ¬ íƒ€ì… (ê¸°ë³¸ê°’: simple)"
                            )
                    
                    comfyui_status = gr.Markdown("")
                    save_comfyui_btn = gr.Button("ğŸ’¾ ComfyUI ì„¤ì • ì €ì¥", variant="primary")
                    
                    def save_comfyui_settings(port_val, workflow_val, model_val, steps_val, cfg_val, sampler_val, scheduler_val):
                        """ComfyUI ì„¤ì • ì €ì¥"""
                        try:
                            env_config = self.load_env_config()
                            
                            # ComfyUI ì„¤ì • ì—…ë°ì´íŠ¸
                            if "comfyui_settings" not in env_config:
                                env_config["comfyui_settings"] = {}
                            
                            workflow_path = f"workflows/{workflow_val}" if workflow_val else "workflows/comfyui_zit.json"
                            
                            env_config["comfyui_settings"]["server_port"] = int(port_val) if port_val else 8000
                            env_config["comfyui_settings"]["workflow_path"] = workflow_path
                            env_config["comfyui_settings"]["model_name"] = model_val or "Zeniji_mix_ZiT_v1.safetensors"
                            env_config["comfyui_settings"]["steps"] = int(steps_val) if steps_val else 9
                            env_config["comfyui_settings"]["cfg"] = float(cfg_val) if cfg_val else 1.0
                            env_config["comfyui_settings"]["sampler_name"] = sampler_val or "euler"
                            env_config["comfyui_settings"]["scheduler"] = scheduler_val or "simple"
                            
                            # í™˜ê²½ì„¤ì • ì €ì¥
                            if self.save_env_config(env_config):
                                # ComfyClient ì¬ì´ˆê¸°í™” (ìƒˆ ì„¤ì • ì ìš©)
                                try:
                                    if self.comfy_client is not None:
                                        server_address = f"127.0.0.1:{env_config['comfyui_settings']['server_port']}"
                                        workflow_path = env_config['comfyui_settings'].get('workflow_path', 'workflows/comfyui_zit.json')
                                        model_name = env_config['comfyui_settings']['model_name']
                                        steps = env_config['comfyui_settings'].get('steps', 9)
                                        cfg = env_config['comfyui_settings'].get('cfg', 1.0)
                                        sampler_name = env_config['comfyui_settings'].get('sampler_name', 'euler')
                                        scheduler = env_config['comfyui_settings'].get('scheduler', 'simple')
                                        self.comfy_client = ComfyClient(
                                            server_address=server_address,
                                            workflow_path=workflow_path,
                                            model_name=model_name,
                                            steps=steps,
                                            cfg=cfg,
                                            sampler_name=sampler_name,
                                            scheduler=scheduler
                                        )
                                        logger.info(f"ComfyClient ì¬ì´ˆê¸°í™” ì™„ë£Œ: {server_address}, workflow: {workflow_path}, model: {model_name}, steps: {steps}, cfg: {cfg}, sampler: {sampler_name}, scheduler: {scheduler}")
                                    return "âœ… ComfyUI ì„¤ì • ì €ì¥ ì™„ë£Œ! (ë‹¤ìŒ ì´ë¯¸ì§€ ìƒì„± ì‹œ ì ìš©ë©ë‹ˆë‹¤)"
                                except Exception as e:
                                    logger.error(f"Failed to reinitialize ComfyClient: {e}")
                                    return f"âœ… ComfyUI ì„¤ì • ì €ì¥ ì™„ë£Œ, í•˜ì§€ë§Œ í´ë¼ì´ì–¸íŠ¸ ì¬ì—°ê²° ì‹¤íŒ¨: {str(e)}"
                            else:
                                return "âŒ ComfyUI ì„¤ì • ì €ì¥ ì‹¤íŒ¨"
                        except Exception as e:
                            logger.error(f"Failed to save ComfyUI settings: {e}")
                            return f"âŒ ComfyUI ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}"
                    
                    save_comfyui_btn.click(
                        save_comfyui_settings,
                        inputs=[comfyui_port_input, comfyui_workflow_input, comfyui_model_input, comfyui_steps_input, comfyui_cfg_input, comfyui_sampler_input, comfyui_scheduler_input],
                        outputs=[comfyui_status]
                    )
            
            # ì²« íƒ­ì˜ ë²„íŠ¼ í´ë¦­ ì‹œ ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸ (íƒ­ ë°–ì—ì„œ ì •ì˜)
            start_btn.click(
                self.validate_and_start,
                inputs=[
                    player_name, player_gender,
                    char_name, char_age, char_gender,
                    appearance, personality,
                    p_val, a_val, d_val, i_val, t_val, dep_val,
                    initial_context, initial_background
                ],
                outputs=[
                    setup_status, tabs,
                    chatbot, gr.Textbox(visible=False), stats_display, image_display,
                    gr.Textbox(visible=False), thought_display, action_display, stats_chart
                ]
            )
            
            # ì„¤ì • ë¡œë“œ ì‹œ UI ì—…ë°ì´íŠ¸
            demo.load(
                enable_chat_ui,
                inputs=[],
                outputs=[submit_btn, user_input]
            )
            
            # Footer ì¶”ê°€
            gr.Markdown(
                """
                <div style="text-align: center; margin-top: 20px; padding: 10px; color: #666;">
                    â¤ï¸ <a href="https://zeniji.love" target="_blank" style="color: #666; text-decoration: none;">zeniji.love</a><br>
                    ğŸ’¬ <a href="https://arca.live/b/zeniji" target="_blank" style="color: #666; text-decoration: none;">ì»¤ë®¤ë‹ˆí‹°</a>
                </div>
                """
            )
        
        return demo


def parse_args():
    parser = argparse.ArgumentParser(description="Zeniji Emotion Simul")
    parser.add_argument("--dev-mode", action="store_true", help="ê°œë°œì ëª¨ë“œ í™œì„±í™”")
    parser.add_argument("--log-level", default="INFO", help="ë¡œê¹… ë ˆë²¨ ì„¤ì •")
    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    args = parse_args()
    logging.getLogger().setLevel(getattr(logging, args.log_level.upper(), logging.INFO))

    app = GameApp(dev_mode=args.dev_mode)
    demo = app.create_ui()
    print("\n" + "=" * 60)
    print("ğŸš€ Gradio ì„œë²„ ì‹œì‘ ì¤‘...")
    print("=" * 60)
    print(f"ğŸ“ ë¡œì»¬ ì ‘ì†: http://localhost:7860")
    print(f"ğŸ“ ë„¤íŠ¸ì›Œí¬ ì ‘ì†: http://127.0.0.1:7860")
    if args.dev_mode:
        print("ğŸ›   Dev Mode ON")
    print("=" * 60 + "\n")
    demo.launch(server_name="127.0.0.1", server_port=7860, share=False, inbrowser=True)


if __name__ == "__main__":
    main()
